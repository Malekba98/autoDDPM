{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnunetv2.inference.predict_from_raw_data import nnUNetPredictor, join\n",
    "\n",
    "import torch\n",
    "predictor = nnUNetPredictor(\n",
    "        tile_step_size=0.5,\n",
    "        use_gaussian=True,\n",
    "        use_mirroring=True,\n",
    "        perform_everything_on_device=True,\n",
    "        device=torch.device('cuda', 0),\n",
    "        verbose=False,\n",
    "        verbose_preprocessing=False,\n",
    "        allow_tqdm=True\n",
    "    )\n",
    "\n",
    "nnUNet_results=\"/home/malek/mock/autoDDPM/nnunet_data/nnunet_results\" \n",
    "\n",
    "predictor.initialize_from_trained_model_folder(\n",
    "        join(nnUNet_results, 'Dataset500_ATLAS/nnUNetTrainer__nnUNetPlans__2d'),\n",
    "        use_folds=(0,1,2,3,4),\n",
    "        checkpoint_name='checkpoint_final.pth',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sitk_stuff': {'spacing': (1.0, 1.0), 'origin': (0.0, 0.0), 'direction': (1.0, 0.0, 0.0, 1.0)}, 'spacing': [999.0, 1.0, 1.0]}\n",
      "(1, 1, 128, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.47it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 71.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 71.73it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 70.41it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 71.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nnUNet_raw is not defined and nnU-Net can only be used on data for which preprocessed files are already present on your system. nnU-Net cannot be used for experiment planning and preprocessing like this. If this is not intended, please read documentation/setting_up_paths.md for information on how to set this up properly.\n",
      "nnUNet_preprocessed is not defined and nnU-Net can not be used for preprocessing or training. If this is not intended, please read documentation/setting_up_paths.md for information on how to set this up.\n",
      "nnUNet_results is not defined and nnU-Net cannot be used for training or inference. If this is not intended behavior, please read documentation/setting_up_paths.md for information on how to set this up.\n",
      "\n",
      "Predicting image of shape torch.Size([1, 1, 128, 108]):\n",
      "perform_everything_on_device: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 64.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 71.23it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 70.28it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 71.49it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 71.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sending off prediction to background worker for resampling\n",
      "\n",
      "Done with image of shape torch.Size([1, 1, 128, 108]):\n"
     ]
    }
   ],
   "source": [
    "from nnunetv2.imageio.simpleitk_reader_writer import SimpleITKIO\n",
    "from nnunetv2.imageio.simpleitk_reader_writer import SimpleITKIO\n",
    "#from nnunetv2.paths import nnUNet_results, nnUNet_raw\n",
    "\n",
    "#print(nnUNet_raw)\n",
    "nnUNet_raw = \"/home/malek/mock/autoDDPM/nnunet_data/nnunet_raw\"\n",
    "\n",
    "img, props = SimpleITKIO().read_images([join(nnUNet_raw, 'Dataset500_ATLAS/imagesTr/ATLAS_002_0000.png')])\n",
    "#img = img[0][0]\n",
    "print(props)\n",
    "print(img.shape)\n",
    "ret = predictor.predict_single_npy_array(img, props, None, None, False)\n",
    "\n",
    "iterator = predictor.get_data_iterator_from_raw_npy_data([img], None, [props], None, 1)\n",
    "ret = predictor.predict_from_data_iterator(iterator, False, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(6, 3))\n",
    "axs[0].imshow(ret[0][0])\n",
    "axs[0].set_title('segmentation')\n",
    "axs[0].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(6, 3))\n",
    "axs[0].imshow(img[0][0])\n",
    "axs[0].set_title('segmentation')\n",
    "axs[0].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(ret))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 128, 128)\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(ret[0].shape)\n",
    "print(ret[0].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(ret[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(6, 3))\n",
    "axs[0].imshow(ret[0][0])\n",
    "axs[0].set_title('segmentation')\n",
    "axs[0].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from nnunetv2.imageio.simpleitk_reader_writer import SimpleITKIO\n",
    "from nnunetv2.imageio.simpleitk_reader_writer import SimpleITKIO\n",
    "#from nnunetv2.paths import nnUNet_results, nnUNet_raw\n",
    "\n",
    "#print(nnUNet_raw)\n",
    "nnUNet_raw = \"/home/malek/mock/autoDDPM/nnunet_data/nnunet_raw\"\n",
    "\n",
    "img, props = SimpleITKIO().read_images([join(nnUNet_raw, 'Dataset500_ATLAS/imagesTr/ATLAS_002_0000.png')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_tensor = torch.zeros((16, 1, 128,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape mock numpy (16, 1, 128, 128)\n",
      "(1, 1, 128, 128)\n",
      "nnUNet_raw is not defined and nnU-Net can only be used on data for which preprocessed files are already present on your system. nnU-Net cannot be used for experiment planning and preprocessing like this. If this is not intended, please read documentation/setting_up_paths.md for information on how to set this up properly.\n",
      "nnUNet_preprocessed is not defined and nnU-Net can not be used for preprocessing or training. If this is not intended, please read documentation/setting_up_paths.md for information on how to set this up.\n",
      "nnUNet_results is not defined and nnU-Net cannot be used for training or inference. If this is not intended behavior, please read documentation/setting_up_paths.md for information on how to set this up.\n",
      "\n",
      "Predicting image of shape torch.Size([1, 1, 128, 128]):\n",
      "perform_everything_on_device: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 71.73it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 75.46it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 75.69it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 75.32it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 75.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sending off prediction to background worker for resampling\n",
      "\n",
      "Done with image of shape torch.Size([1, 1, 128, 128]):\n",
      "\n",
      "Predicting image of shape torch.Size([1, 1, 128, 128]):\n",
      "perform_everything_on_device: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 75.07it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 75.30it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 74.25it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 75.62it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 76.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sending off prediction to background worker for resampling\n",
      "\n",
      "Done with image of shape torch.Size([1, 1, 128, 128]):\n",
      "\n",
      "Predicting image of shape torch.Size([1, 1, 128, 128]):\n",
      "perform_everything_on_device: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 74.05it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 74.70it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 75.60it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 75.19it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 75.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sending off prediction to background worker for resampling\n",
      "\n",
      "Done with image of shape torch.Size([1, 1, 128, 128]):\n",
      "\n",
      "Predicting image of shape torch.Size([1, 1, 128, 128]):\n",
      "perform_everything_on_device: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 74.37it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 74.56it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 74.89it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 75.39it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 74.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sending off prediction to background worker for resampling\n",
      "\n",
      "Done with image of shape torch.Size([1, 1, 128, 128]):\n",
      "\n",
      "Predicting image of shape torch.Size([1, 1, 128, 128]):\n",
      "perform_everything_on_device: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 74.04it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 75.25it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 75.44it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 75.89it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 74.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sending off prediction to background worker for resampling\n",
      "\n",
      "Done with image of shape torch.Size([1, 1, 128, 128]):\n",
      "\n",
      "Predicting image of shape torch.Size([1, 1, 128, 128]):\n",
      "perform_everything_on_device: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 74.56it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 75.32it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 74.69it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 75.15it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 74.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sending off prediction to background worker for resampling\n",
      "\n",
      "Done with image of shape torch.Size([1, 1, 128, 128]):\n",
      "\n",
      "Predicting image of shape torch.Size([1, 1, 128, 128]):\n",
      "perform_everything_on_device: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 73.96it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 74.77it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 74.93it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 75.41it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 74.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sending off prediction to background worker for resampling\n",
      "\n",
      "Done with image of shape torch.Size([1, 1, 128, 128]):\n",
      "\n",
      "Predicting image of shape torch.Size([1, 1, 128, 128]):\n",
      "perform_everything_on_device: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 73.71it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 74.69it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 74.23it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 75.58it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 74.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sending off prediction to background worker for resampling\n",
      "\n",
      "Done with image of shape torch.Size([1, 1, 128, 128]):\n",
      "\n",
      "Predicting image of shape torch.Size([1, 1, 128, 128]):\n",
      "perform_everything_on_device: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 73.96it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 74.82it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 74.85it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 75.19it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 74.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sending off prediction to background worker for resampling\n",
      "\n",
      "Done with image of shape torch.Size([1, 1, 128, 128]):\n",
      "\n",
      "Predicting image of shape torch.Size([1, 1, 128, 128]):\n",
      "perform_everything_on_device: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 74.13it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 74.65it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 75.95it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 76.03it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 75.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sending off prediction to background worker for resampling\n",
      "\n",
      "Done with image of shape torch.Size([1, 1, 128, 128]):\n",
      "\n",
      "Predicting image of shape torch.Size([1, 1, 128, 128]):\n",
      "perform_everything_on_device: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 74.63it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 75.07it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 75.69it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 75.70it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 75.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sending off prediction to background worker for resampling\n",
      "\n",
      "Done with image of shape torch.Size([1, 1, 128, 128]):\n",
      "\n",
      "Predicting image of shape torch.Size([1, 1, 128, 128]):\n",
      "perform_everything_on_device: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 62.30it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 74.77it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 75.73it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 76.23it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 75.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sending off prediction to background worker for resampling\n",
      "\n",
      "Done with image of shape torch.Size([1, 1, 128, 128]):\n",
      "\n",
      "Predicting image of shape torch.Size([1, 1, 128, 128]):\n",
      "perform_everything_on_device: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 74.83it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 75.81it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 71.97it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 74.47it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 73.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sending off prediction to background worker for resampling\n",
      "\n",
      "Done with image of shape torch.Size([1, 1, 128, 128]):\n",
      "\n",
      "Predicting image of shape torch.Size([1, 1, 128, 128]):\n",
      "perform_everything_on_device: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 75.75it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 75.42it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 75.28it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 75.25it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 74.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sending off prediction to background worker for resampling\n",
      "\n",
      "Done with image of shape torch.Size([1, 1, 128, 128]):\n",
      "\n",
      "Predicting image of shape torch.Size([1, 1, 128, 128]):\n",
      "perform_everything_on_device: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 75.10it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 75.09it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 75.06it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 76.24it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 76.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sending off prediction to background worker for resampling\n",
      "\n",
      "Done with image of shape torch.Size([1, 1, 128, 128]):\n",
      "\n",
      "Predicting image of shape torch.Size([1, 1, 128, 128]):\n",
      "perform_everything_on_device: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 75.46it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 76.08it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 75.89it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 75.35it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 74.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sending off prediction to background worker for resampling\n",
      "\n",
      "Done with image of shape torch.Size([1, 1, 128, 128]):\n"
     ]
    }
   ],
   "source": [
    "#mock_tensor.shape\n",
    "import numpy as np\n",
    "\n",
    "mock_numpy = mock_tensor.numpy()\n",
    "print('shape mock numpy', mock_numpy.shape)\n",
    "mock_list = [mock_numpy[i] for i in range(16)]\n",
    "mock_list = [np.expand_dims(mock_list[i], axis=0) for i in range(16)]\n",
    "\n",
    "print(mock_list[0].shape)\n",
    "iterator = predictor.get_data_iterator_from_raw_npy_data(mock_list, None, [props for _ in range(16)], None, 1)\n",
    "ret = predictor.predict_from_data_iterator(iterator, False, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret[0].shape\n",
    "type(ret[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make list that contains 16 numpy arrays from tensor of shape (16, 1, 128, 128)\n",
    "mock_tensor = torch.zeros((16, 1, 128,128))\n",
    "# cast this tensor to numpy array\n",
    "mock_numpy = mock_tensor.numpy()\n",
    "# create list of 16 numpy arrays of shape (1,1,128,128)\n",
    "mock_list = [mock_numpy[i] for i in range(16)]\n",
    "# add dimensions to each numpy array in the list\n",
    "mock_list = [np.expand_dims(mock_list[i], axis=0) for i in range(16)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(ret[0][0], cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(img[0][0], cmap='gray')\n",
    "plt.savefig('image.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nnunet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnnunet\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nnunet'"
     ]
    }
   ],
   "source": [
    "import nnunet\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnunet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
