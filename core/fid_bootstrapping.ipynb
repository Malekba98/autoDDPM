{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/malek/mock\n"
     ]
    }
   ],
   "source": [
    "import monai\n",
    "import torch\n",
    "\n",
    "image_dir_no_patho = [\"./data/ATLAS/splits_healthy_54_sample/Atlas_healthy.csv\"]\n",
    "image_dir_patho_reference = [\"./data/ATLAS/splits_reference_test_unhealthy_54_samples/atlas_test_png.csv\"]\n",
    "image_dir_patho_reference_same_atlas = [\"./data/ATLAS/splits_over_1_stratified_all_splits/atlas_test_png.csv\"]\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "from torch.utils.data import DataLoader\n",
    "import sys\n",
    "import os\n",
    "\n",
    "os.chdir('/home/malek/mock/autoDDPM')\n",
    "dir_path = os.path.dirname(os.path.realpath(os.getcwd()))\n",
    "\n",
    "\n",
    "# Get the parent directory\n",
    "# Add the parent directory to the system path\n",
    "sys.path.append(dir_path)\n",
    "print(dir_path)\n",
    "from data.loaders.ixi_loader import mask_preprocessing_loader, AtlasLoader, IXILoaderHarmonize, AtlasLoaderHarmonize\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "dataset_no_patho = AtlasLoader(\n",
    "            image_dir_no_patho,\n",
    "            target_size=(128, 128),\n",
    "            test=False,\n",
    "        )\n",
    "\n",
    "loader_no_patho = DataLoader(\n",
    "    dataset_no_patho, batch_size=54, shuffle=False, drop_last=False, pin_memory=True\n",
    ")\n",
    "\n",
    "dataset_patho_referemce = AtlasLoader(\n",
    "            image_dir_patho_reference,\n",
    "            target_size=(128, 128),\n",
    "            test=False,\n",
    "        )\n",
    "\n",
    "loader_patho_reference = DataLoader(\n",
    "    dataset_patho_referemce, batch_size=54, shuffle=False, drop_last=False, pin_memory=True\n",
    ")\n",
    "\n",
    "dataset_patho_referemce_same_atlas = AtlasLoader(\n",
    "            image_dir_patho_reference_same_atlas,\n",
    "            target_size=(128, 128),\n",
    "            test=False,\n",
    "        )\n",
    "\n",
    "loader_patho_reference_same_atlas = DataLoader(\n",
    "    dataset_patho_referemce_same_atlas, batch_size=54, shuffle=False, drop_last=False, pin_memory=True\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/malek/.cache/torch/hub/Warvito_radimagenet-models_main\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet50(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "  (bn1): BatchNorm2d(64, eps=1.001e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(256, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(256, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(256, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(2, 2))\n",
       "      (bn1): BatchNorm2d(128, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(512, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): BatchNorm2d(512, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(128, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(512, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(128, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(512, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(128, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(512, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "      (bn1): BatchNorm2d(256, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(1024, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): BatchNorm2d(1024, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(256, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(1024, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(256, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(1024, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(256, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(1024, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(256, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(1024, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(256, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(1024, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(2, 2))\n",
       "      (bn1): BatchNorm2d(512, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(512, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(2048, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): BatchNorm2d(2048, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(512, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(512, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(2048, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(512, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(512, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(2048, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from generative.metrics import FIDMetric, MMDMetric, MultiScaleSSIMMetric, SSIMMetric\n",
    "\n",
    "radnet = torch.hub.load(\"Warvito/radimagenet-models:main\", model=\"radimagenet_resnet50\",verbose=True)\n",
    "\n",
    "radnet.to(device)\n",
    "radnet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtract_mean(x: torch.Tensor) -> torch.Tensor:\n",
    "    mean = [0.406, 0.456, 0.485]\n",
    "    x[:, 0, :, :] -= mean[0]\n",
    "    x[:, 1, :, :] -= mean[1]\n",
    "    x[:, 2, :, :] -= mean[2]\n",
    "    return x\n",
    "\n",
    "\n",
    "def spatial_average(x: torch.Tensor, keepdim: bool = True) -> torch.Tensor:\n",
    "    return x.mean([2, 3], keepdim=keepdim)\n",
    "\n",
    "\n",
    "def get_features(image):\n",
    "    # If input has just 1 channel, repeat channel to have 3 channels\n",
    "    if image.shape[1]:\n",
    "        image = image.repeat(1, 3, 1, 1)\n",
    "\n",
    "    # Change order from 'RGB' to 'BGR'\n",
    "    image = image[:, [2, 1, 0], ...]\n",
    "\n",
    "    # Subtract mean used during training\n",
    "    image = subtract_mean(image)\n",
    "\n",
    "    # Get model outputs\n",
    "    with torch.no_grad():\n",
    "        feature_image = radnet.forward(image)\n",
    "        # flattens the image spatially\n",
    "        feature_image = spatial_average(feature_image, keepdim=False)\n",
    "\n",
    "    return feature_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of images_no_patho torch.Size([53, 1, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "for (data_1,data_2,data_3) in zip(loader_no_patho,loader_patho_reference,loader_patho_reference_same_atlas):\n",
    "    images_no_patho = data_1[0].to(device)\n",
    "    images_patho_reference = data_2[0].to(device)\n",
    "    images_patho_reference_same_atlas = data_3[0].to(device)\n",
    "    \n",
    "    \n",
    "    print(\"shape of images_no_patho\",images_no_patho.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "shape of tensor torch.Size([54, 3, 128, 128])\n",
      "shape of tensor torch.Size([54, 3, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "from ast import List\n",
    "from dl_utils.fid_score import save_fid_stats, calculate_fid_given_images\n",
    "device = torch.device('cuda' if (torch.cuda.is_available()) else 'cpu')\n",
    "print('device:', device)\n",
    "num_workers = 4\n",
    "\n",
    "List_of_images = [images_no_patho,images_patho_reference]\n",
    "\n",
    "fid_value = calculate_fid_given_images(List_of_images,\n",
    "                                        54,\n",
    "                                        device,\n",
    "                                        2048,\n",
    "                                        num_workers)\n",
    "\n",
    "#print('FID: ', fid_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score Radnet between pathological (reference) and non pathological Atlas subsets\n",
      "FID Score Radnet: 6.30\n",
      "FID score InceptionNet: 40.84\n"
     ]
    }
   ],
   "source": [
    "synth_features = []\n",
    "real_features = []\n",
    "\n",
    "real_eval_feats = get_features(images_no_patho)\n",
    "#print('real_eval_feats shape',real_eval_feats.shape)\n",
    "real_features.append(real_eval_feats)\n",
    "#print('real features shape ',len(real_features))\n",
    "\n",
    "# Get the features for the synthetic data\n",
    "synth_eval_feats = get_features(images_patho_reference)\n",
    "synth_features.append(synth_eval_feats)\n",
    "\n",
    "synth_features = torch.vstack(synth_features)\n",
    "real_features = torch.vstack(real_features)\n",
    "#print('shape of real features tensor',real_features.shape)\n",
    "\n",
    "fid = FIDMetric()\n",
    "fid_res = fid(synth_features, real_features)\n",
    "\n",
    "print('FID score Radnet between pathological (reference) and non pathological Atlas subsets')\n",
    "print(f\"FID Score Radnet: {fid_res.item():.2f}\")\n",
    "print(f'FID score InceptionNet: {fid_value:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of tensor torch.Size([54, 3, 128, 128])\n",
      "shape of tensor torch.Size([54, 3, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "List_of_images = [images_no_patho,images_patho_reference_same_atlas]\n",
    "\n",
    "fid_value = calculate_fid_given_images(List_of_images,\n",
    "                                        54,\n",
    "                                        device,\n",
    "                                        2048,\n",
    "                                        num_workers)\n",
    "\n",
    "#print('FID: ', fid_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fid_radnet(images_1,images_2):\n",
    "    synth_features = []\n",
    "    real_features = []\n",
    "\n",
    "    real_eval_feats = get_features(images_1)\n",
    "    real_features.append(real_eval_feats)\n",
    "\n",
    "    # Get the features for the synthetic data\n",
    "    synth_eval_feats = get_features(images_2)\n",
    "    synth_features.append(synth_eval_feats)\n",
    "\n",
    "    synth_features = torch.vstack(synth_features)\n",
    "    real_features = torch.vstack(real_features)\n",
    "\n",
    "    fid = FIDMetric()\n",
    "    fid_res = fid(synth_features, real_features)\n",
    "    fid_res= round(fid_res.item(), 2)\n",
    "\n",
    "    return fid_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score between pathological (reference same atlas split) and non pathological Atlas subsets\n",
      "FID Score: 7.9\n",
      "FID Score InceptionNet: 35.39\n"
     ]
    }
   ],
   "source": [
    "fid_res = compute_fid_radnet(images_no_patho,images_patho_reference_same_atlas)\n",
    "print('FID score between pathological (reference same atlas split) and non pathological Atlas subsets')\n",
    "print(f\"FID Score: {fid_res}\")\n",
    "\n",
    "print(f\"FID Score InceptionNet: {fid_value:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset, RandomSampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset, RandomSampler\n",
    "\n",
    "torch.manual_seed(42)\n",
    "# Create a list to store the loaders\n",
    "loaders_patho_reference_same_atlas = []\n",
    "\n",
    "# Loop 10 times to create multiple instances of the loaders\n",
    "for _ in range(10):\n",
    "    # Create a new instance of AtlasLoader\n",
    "    dataset_patho_reference_same_atlas = AtlasLoader(\n",
    "        image_dir_patho_reference_same_atlas,\n",
    "        target_size=(128, 128),\n",
    "        test=False,\n",
    "    )\n",
    "    sampler = RandomSampler(dataset_patho_reference_same_atlas, replacement=True)\n",
    "\n",
    "    # Create a new instance of DataLoader\n",
    "    loader_patho_reference_same_atlas = DataLoader(\n",
    "        dataset_patho_reference_same_atlas, batch_size=54, shuffle=False, drop_last=False, pin_memory=True, sampler=sampler\n",
    "    )\n",
    "\n",
    "    # Append the new loaders to the list\n",
    "    loaders_patho_reference_same_atlas.append(loader_patho_reference_same_atlas)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean FID Score: 8.51\n",
      "Standard Deviation: 0.53\n"
     ]
    }
   ],
   "source": [
    "from numpy import std\n",
    "\n",
    "sum_ = 0\n",
    "fids = []\n",
    "for data in loaders_patho_reference_same_atlas:\n",
    "    for images in data:\n",
    "        images_patho_reference_same_atlas = images[0].to(device)\n",
    "        #print(\"shape of images_patho_reference_same_atlas\",images_patho_reference_same_atlas.shape)\n",
    "        fid = compute_fid_radnet(images_no_patho,images_patho_reference_same_atlas)\n",
    "        sum_ += fid\n",
    "        fids.append(fid)\n",
    "\n",
    "mean = sum_/10\n",
    "print(f\"Mean FID Score: {mean:.2f}\")\n",
    "std_ = std(fids)\n",
    "print(f\"Standard Deviation: {std_:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score between pathological (reference same atlas split) and non pathological Atlas subsets\n",
      "FID Score: 9.058\n",
      "FID score between pathological (reference same atlas split) and non pathological Atlas subsets\n",
      "FID Score: 8.599\n",
      "FID score between pathological (reference same atlas split) and non pathological Atlas subsets\n",
      "FID Score: 7.804\n",
      "FID score between pathological (reference same atlas split) and non pathological Atlas subsets\n",
      "FID Score: 8.642\n",
      "FID score between pathological (reference same atlas split) and non pathological Atlas subsets\n",
      "FID Score: 8.292\n",
      "FID score between pathological (reference same atlas split) and non pathological Atlas subsets\n",
      "FID Score: 7.91\n",
      "FID score between pathological (reference same atlas split) and non pathological Atlas subsets\n",
      "FID Score: 8.467\n",
      "FID score between pathological (reference same atlas split) and non pathological Atlas subsets\n",
      "FID Score: 8.448\n",
      "FID score between pathological (reference same atlas split) and non pathological Atlas subsets\n",
      "FID Score: 8.274\n",
      "FID score between pathological (reference same atlas split) and non pathological Atlas subsets\n",
      "FID Score: 7.901\n",
      "83.395\n",
      "Mean FID Score: 8.34\n",
      "Standard Deviation: 0.37\n"
     ]
    }
   ],
   "source": [
    "from numpy import std\n",
    "\n",
    "sum_ = 0\n",
    "fids = []\n",
    "for data in loaders_patho_reference_same_atlas:\n",
    "    for images in data:\n",
    "        images_patho_reference_same_atlas = images[0].to(device)\n",
    "        #print(\"shape of images_patho_reference_same_atlas\",images_patho_reference_same_atlas.shape)\n",
    "        fid = compute_fid_radnet(images_no_patho,images_patho_reference_same_atlas)\n",
    "        sum_ += fid\n",
    "        fids.append(fid)\n",
    "\n",
    "mean = sum_/10\n",
    "print(f\"Mean FID Score: {mean:.2f}\")\n",
    "std_ = std(fids)\n",
    "print(f\"Standard Deviation: {std_:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6, 1, 4, 9, 1, 0, 6, 4, 3, 7])\n",
      "torch.Size([10, 3, 128, 18])\n",
      "tensor([4, 6, 9, 4, 9, 2, 8, 7, 3, 8])\n",
      "torch.Size([10, 3, 128, 18])\n",
      "tensor([2, 0, 5, 4, 2, 4, 2, 0, 5, 4])\n",
      "torch.Size([10, 3, 128, 18])\n",
      "tensor([8, 2, 1, 7, 7, 3, 7, 2, 5, 8])\n",
      "torch.Size([10, 3, 128, 18])\n",
      "tensor([8, 4, 2, 5, 8, 6, 1, 7, 2, 7])\n",
      "torch.Size([10, 3, 128, 18])\n",
      "tensor([1, 9, 6, 9, 2, 3, 9, 5, 3, 5])\n",
      "torch.Size([10, 3, 128, 18])\n",
      "tensor([5, 0, 8, 0, 0, 6, 5, 9, 0, 2])\n",
      "torch.Size([10, 3, 128, 18])\n",
      "tensor([0, 5, 6, 7, 5, 3, 8, 6, 6, 8])\n",
      "torch.Size([10, 3, 128, 18])\n",
      "tensor([9, 5, 6, 2, 4, 2, 8, 4, 0, 4])\n",
      "torch.Size([10, 3, 128, 18])\n",
      "tensor([8, 4, 8, 1, 0, 6, 7, 9, 0, 7])\n",
      "torch.Size([10, 3, 128, 18])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "# Set the random seed\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Assume input is a tensor of shape [b, c, 128, 18]\n",
    "b, c = 10, 3\n",
    "input_tensor = torch.rand(b, c, 128, 18)\n",
    "\n",
    "# Generate random indices\n",
    "indices = torch.randint(b, (b,))\n",
    "print(indices)\n",
    "\n",
    "# Use the indices to index into the tensor\n",
    "sampled_tensor = input_tensor[indices]\n",
    "\n",
    "print(sampled_tensor.shape)  # Prints: torch.Size([b, c, 128, 18])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Assume input is a tensor of shape [b, c, 128, 18]\n",
    "b, c = 10, 3\n",
    "torch.manual_seed(seed=42)\n",
    "input_tensor = torch.rand(b, c, 128, 18)\n",
    "\n",
    "# Sample with replacement from the tensor 10 times\n",
    "for _ in range(10):\n",
    "    # Generate random indices\n",
    "    indices = torch.randint(b, (b,))\n",
    "    print(indices.shape)\n",
    "\n",
    "    # Use the indices to index into the tensor\n",
    "    sampled_tensor = input_tensor[indices]\n",
    "\n",
    "    #print(sampled_tensor.shape)  # Prints: torch.Size([b, c, 128, 18])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[39, 23, 32, 36, 39, 52, 46, 23, 50, 7, 40, 27, 26, 36, 24, 20, 31, 0, 34, 28, 25, 33, 26, 11, 43, 42, 44, 45, 24, 21, 3, 14, 33, 52, 36, 15, 52, 40, 22, 32, 51, 29, 37, 16, 27, 50, 19, 40, 52, 25, 29, 49, 6], [38, 5, 5, 5, 24, 7, 32, 14, 44, 41, 27, 41, 52, 26, 25, 50, 52, 1, 10, 18, 26, 50, 52, 14, 30, 41, 20, 36, 28, 6, 8, 44, 27, 24, 3, 3, 22, 39, 11, 14, 18, 52, 16, 36, 45, 45, 50, 38, 10, 47, 41, 6, 13], [15, 15, 22, 7, 52, 15, 10, 13, 32, 15, 3, 46, 15, 51, 28, 32, 38, 11, 0, 7, 32, 15, 20, 33, 16, 34, 7, 17, 10, 40, 19, 11, 41, 41, 16, 20, 17, 11, 47, 18, 38, 23, 22, 1, 2, 38, 18, 48, 40, 15, 29, 35, 18], [48, 24, 52, 11, 36, 27, 48, 34, 52, 19, 21, 28, 40, 12, 47, 27, 23, 30, 49, 40, 32, 32, 18, 15, 0, 49, 36, 14, 49, 19, 2, 26, 41, 6, 1, 26, 4, 37, 39, 26, 15, 36, 6, 49, 19, 0, 35, 36, 12, 33, 29, 2, 44], [31, 24, 23, 52, 32, 52, 17, 47, 52, 21, 25, 43, 39, 45, 13, 15, 45, 38, 10, 13, 50, 40, 52, 50, 32, 26, 17, 5, 9, 51, 22, 26, 50, 33, 38, 15, 48, 25, 8, 43, 48, 0, 26, 3, 34, 38, 34, 51, 48, 21, 36, 52, 10], [14, 43, 43, 45, 25, 35, 17, 26, 13, 42, 48, 29, 37, 12, 24, 52, 47, 50, 47, 44, 14, 29, 2, 36, 33, 4, 46, 3, 48, 26, 40, 3, 22, 26, 40, 6, 7, 17, 0, 35, 52, 22, 20, 10, 47, 1, 44, 11, 30, 11, 19, 12, 29], [44, 38, 30, 4, 25, 28, 15, 42, 22, 11, 33, 27, 25, 25, 23, 1, 19, 18, 0, 6, 42, 33, 2, 52, 41, 16, 29, 46, 9, 0, 31, 32, 43, 13, 17, 0, 25, 13, 10, 22, 36, 14, 25, 20, 29, 28, 36, 43, 28, 2, 12, 52, 50], [0, 21, 35, 14, 7, 10, 52, 13, 19, 40, 35, 44, 24, 32, 21, 20, 30, 23, 46, 21, 30, 19, 16, 12, 10, 7, 4, 8, 30, 37, 5, 51, 20, 51, 8, 11, 23, 40, 14, 20, 0, 24, 27, 7, 24, 28, 52, 30, 18, 16, 2, 24, 10], [38, 49, 38, 12, 8, 16, 10, 38, 14, 51, 43, 25, 29, 37, 4, 49, 10, 12, 25, 18, 10, 3, 9, 11, 2, 21, 32, 48, 22, 37, 50, 25, 27, 45, 2, 43, 44, 31, 52, 23, 39, 24, 49, 27, 7, 0, 6, 18, 15, 15, 23, 8, 21], [27, 46, 28, 13, 20, 41, 17, 6, 48, 8, 32, 13, 0, 46, 0, 35, 50, 23, 42, 0, 0, 28, 36, 12, 51, 34, 52, 43, 36, 25, 40, 11, 48, 14, 47, 37, 29, 12, 22, 45, 29, 20, 47, 46, 30, 34, 8, 45, 4, 49, 7, 36, 33]]\n",
      "torch.Size([10, 53])\n",
      "shape of indices torch.Size([10, 53])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(seed=42)\n",
    "\n",
    "#print(indices)\n",
    "indices = torch.randint(53, (10, 53,))\n",
    "indices_list = indices.tolist()\n",
    "print(indices_list)\n",
    "\n",
    "indices = torch.tensor(indices_list)\n",
    "print(indices.shape)\n",
    "\n",
    "print('shape of indices',indices.shape)\n",
    "for i in range(indices.shape[0]):\n",
    "    indices_ = indices[i]\n",
    "    #print(indices_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "braincf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
