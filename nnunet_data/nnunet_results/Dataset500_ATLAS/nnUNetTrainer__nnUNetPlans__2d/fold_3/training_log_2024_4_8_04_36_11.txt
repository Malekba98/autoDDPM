
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 32, 'patch_size': [128, 112], 'median_image_size_in_voxels': [128.0, 108.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 5, 'features_per_stage': [32, 64, 128, 256, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset500_ATLAS', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [999.0, 1.0, 1.0], 'original_median_shape_after_transp': [1, 128, 108], 'image_reader_writer': 'NaturalImage2DIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 255.0, 'mean': 106.32513488594138, 'median': 104.0, 'min': 5.0, 'percentile_00_5': 13.0, 'percentile_99_5': 225.0, 'std': 45.25044338801177}}} 
 
2024-04-08 04:36:12.951714: unpacking dataset... 
2024-04-08 04:36:15.686870: unpacking done... 
2024-04-08 04:36:15.687594: do_dummy_2d_data_aug: False 
2024-04-08 04:36:15.691518: Using splits from existing split file: /home/malek/autoDDPM/nnunet_data/nnunet_preprocessed/Dataset500_ATLAS/splits_final.json 
2024-04-08 04:36:15.692046: The split file contains 5 splits. 
2024-04-08 04:36:15.692107: Desired fold for training: 3 
2024-04-08 04:36:15.692154: This split has 524 training and 131 validation cases. 
2024-04-08 04:36:15.700276: Unable to plot network architecture: 
2024-04-08 04:36:15.700334: No module named 'hiddenlayer' 
2024-04-08 04:36:15.705638:  
2024-04-08 04:36:15.705725: Epoch 0 
2024-04-08 04:36:15.705834: Current learning rate: 0.01 
2024-04-08 04:36:28.653492: train_loss -0.0745 
2024-04-08 04:36:28.653970: val_loss -0.5646 
2024-04-08 04:36:28.654093: Pseudo dice [0.6446] 
2024-04-08 04:36:28.654165: Epoch time: 12.95 s 
2024-04-08 04:36:28.654423: Yayy! New best EMA pseudo Dice: 0.6446 
2024-04-08 04:36:29.622599:  
2024-04-08 04:36:29.622701: Epoch 1 
2024-04-08 04:36:29.622794: Current learning rate: 0.00999 
2024-04-08 04:36:38.552201: train_loss -0.5932 
2024-04-08 04:36:38.552495: val_loss -0.6782 
2024-04-08 04:36:38.552671: Pseudo dice [0.7321] 
2024-04-08 04:36:38.552742: Epoch time: 8.93 s 
2024-04-08 04:36:38.552794: Yayy! New best EMA pseudo Dice: 0.6534 
2024-04-08 04:36:39.624095:  
2024-04-08 04:36:39.624218: Epoch 2 
2024-04-08 04:36:39.624323: Current learning rate: 0.00998 
2024-04-08 04:36:48.548145: train_loss -0.6698 
2024-04-08 04:36:48.548285: val_loss -0.6834 
2024-04-08 04:36:48.548346: Pseudo dice [0.7335] 
2024-04-08 04:36:48.548404: Epoch time: 8.92 s 
2024-04-08 04:36:48.548466: Yayy! New best EMA pseudo Dice: 0.6614 
2024-04-08 04:36:49.710515:  
2024-04-08 04:36:49.710752: Epoch 3 
2024-04-08 04:36:49.710837: Current learning rate: 0.00997 
2024-04-08 04:36:58.920232: train_loss -0.7204 
2024-04-08 04:36:58.920479: val_loss -0.6845 
2024-04-08 04:36:58.920580: Pseudo dice [0.7403] 
2024-04-08 04:36:58.920645: Epoch time: 9.21 s 
2024-04-08 04:36:58.920696: Yayy! New best EMA pseudo Dice: 0.6693 
2024-04-08 04:37:00.171890:  
2024-04-08 04:37:00.172009: Epoch 4 
2024-04-08 04:37:00.172105: Current learning rate: 0.00996 
2024-04-08 04:37:09.560931: train_loss -0.7262 
2024-04-08 04:37:09.561087: val_loss -0.726 
2024-04-08 04:37:09.561172: Pseudo dice [0.776] 
2024-04-08 04:37:09.561252: Epoch time: 9.39 s 
2024-04-08 04:37:09.561319: Yayy! New best EMA pseudo Dice: 0.6799 
2024-04-08 04:37:10.795569:  
2024-04-08 04:37:10.795667: Epoch 5 
2024-04-08 04:37:10.795763: Current learning rate: 0.00995 
2024-04-08 04:37:19.700095: train_loss -0.7504 
2024-04-08 04:37:19.700268: val_loss -0.7326 
2024-04-08 04:37:19.700349: Pseudo dice [0.775] 
2024-04-08 04:37:19.700425: Epoch time: 8.91 s 
2024-04-08 04:37:19.700508: Yayy! New best EMA pseudo Dice: 0.6894 
2024-04-08 04:37:20.816704:  
2024-04-08 04:37:20.816802: Epoch 6 
2024-04-08 04:37:20.816881: Current learning rate: 0.00995 
2024-04-08 04:37:29.547725: train_loss -0.7638 
2024-04-08 04:37:29.547936: val_loss -0.7355 
2024-04-08 04:37:29.548000: Pseudo dice [0.7797] 
2024-04-08 04:37:29.548138: Epoch time: 8.73 s 
2024-04-08 04:37:29.548187: Yayy! New best EMA pseudo Dice: 0.6985 
2024-04-08 04:37:30.661703:  
2024-04-08 04:37:30.661816: Epoch 7 
2024-04-08 04:37:30.661915: Current learning rate: 0.00994 
2024-04-08 04:37:39.960486: train_loss -0.7763 
2024-04-08 04:37:39.960657: val_loss -0.7414 
2024-04-08 04:37:39.960716: Pseudo dice [0.7931] 
2024-04-08 04:37:39.960771: Epoch time: 9.3 s 
2024-04-08 04:37:39.960814: Yayy! New best EMA pseudo Dice: 0.7079 
2024-04-08 04:37:41.088249:  
2024-04-08 04:37:41.088349: Epoch 8 
2024-04-08 04:37:41.088453: Current learning rate: 0.00993 
2024-04-08 04:37:50.568901: train_loss -0.7867 
2024-04-08 04:37:50.569290: val_loss -0.7599 
2024-04-08 04:37:50.569400: Pseudo dice [0.8062] 
2024-04-08 04:37:50.569474: Epoch time: 9.48 s 
2024-04-08 04:37:50.569605: Yayy! New best EMA pseudo Dice: 0.7178 
2024-04-08 04:37:51.879129:  
2024-04-08 04:37:51.879246: Epoch 9 
2024-04-08 04:37:51.879343: Current learning rate: 0.00992 
2024-04-08 04:38:01.253656: train_loss -0.7933 
2024-04-08 04:38:01.253850: val_loss -0.7521 
2024-04-08 04:38:01.253944: Pseudo dice [0.8012] 
2024-04-08 04:38:01.254033: Epoch time: 9.38 s 
2024-04-08 04:38:01.254109: Yayy! New best EMA pseudo Dice: 0.7261 
2024-04-08 04:38:02.347456:  
2024-04-08 04:38:02.347569: Epoch 10 
2024-04-08 04:38:02.347664: Current learning rate: 0.00991 
2024-04-08 04:38:11.662187: train_loss -0.8016 
2024-04-08 04:38:11.662342: val_loss -0.7311 
2024-04-08 04:38:11.662416: Pseudo dice [0.7789] 
2024-04-08 04:38:11.662483: Epoch time: 9.32 s 
2024-04-08 04:38:11.662540: Yayy! New best EMA pseudo Dice: 0.7314 
2024-04-08 04:38:12.798247:  
2024-04-08 04:38:12.798342: Epoch 11 
2024-04-08 04:38:12.798452: Current learning rate: 0.0099 
2024-04-08 04:38:21.744048: train_loss -0.8088 
2024-04-08 04:38:21.744195: val_loss -0.7505 
2024-04-08 04:38:21.744304: Pseudo dice [0.7939] 
2024-04-08 04:38:21.744400: Epoch time: 8.95 s 
2024-04-08 04:38:21.744487: Yayy! New best EMA pseudo Dice: 0.7376 
2024-04-08 04:38:22.901787:  
2024-04-08 04:38:22.901906: Epoch 12 
2024-04-08 04:38:22.901988: Current learning rate: 0.00989 
2024-04-08 04:38:31.670468: train_loss -0.813 
2024-04-08 04:38:31.670606: val_loss -0.768 
2024-04-08 04:38:31.670830: Pseudo dice [0.8059] 
2024-04-08 04:38:31.670917: Epoch time: 8.77 s 
2024-04-08 04:38:31.671061: Yayy! New best EMA pseudo Dice: 0.7445 
2024-04-08 04:38:32.880323:  
2024-04-08 04:38:32.880680: Epoch 13 
2024-04-08 04:38:32.880904: Current learning rate: 0.00988 
2024-04-08 04:38:42.453441: train_loss -0.8181 
2024-04-08 04:38:42.453648: val_loss -0.7439 
2024-04-08 04:38:42.453757: Pseudo dice [0.7905] 
2024-04-08 04:38:42.453860: Epoch time: 9.57 s 
2024-04-08 04:38:42.453948: Yayy! New best EMA pseudo Dice: 0.7491 
2024-04-08 04:38:43.767895:  
2024-04-08 04:38:43.768002: Epoch 14 
2024-04-08 04:38:43.768083: Current learning rate: 0.00987 
2024-04-08 04:38:52.514412: train_loss -0.8254 
2024-04-08 04:38:52.514639: val_loss -0.7327 
2024-04-08 04:38:52.514706: Pseudo dice [0.7851] 
2024-04-08 04:38:52.514767: Epoch time: 8.75 s 
2024-04-08 04:38:52.514874: Yayy! New best EMA pseudo Dice: 0.7527 
2024-04-08 04:38:53.671820:  
2024-04-08 04:38:53.671939: Epoch 15 
2024-04-08 04:38:53.672034: Current learning rate: 0.00986 
2024-04-08 04:39:02.852984: train_loss -0.8276 
2024-04-08 04:39:02.853339: val_loss -0.7536 
2024-04-08 04:39:02.853471: Pseudo dice [0.7978] 
2024-04-08 04:39:02.853684: Epoch time: 9.18 s 
2024-04-08 04:39:02.853735: Yayy! New best EMA pseudo Dice: 0.7572 
2024-04-08 04:39:04.025255:  
2024-04-08 04:39:04.025503: Epoch 16 
2024-04-08 04:39:04.025703: Current learning rate: 0.00986 
2024-04-08 04:39:13.330661: train_loss -0.8362 
2024-04-08 04:39:13.330922: val_loss -0.7685 
2024-04-08 04:39:13.331168: Pseudo dice [0.8118] 
2024-04-08 04:39:13.331263: Epoch time: 9.31 s 
2024-04-08 04:39:13.331339: Yayy! New best EMA pseudo Dice: 0.7626 
2024-04-08 04:39:14.478599:  
2024-04-08 04:39:14.478827: Epoch 17 
2024-04-08 04:39:14.478908: Current learning rate: 0.00985 
2024-04-08 04:39:23.450219: train_loss -0.8368 
2024-04-08 04:39:23.450416: val_loss -0.7689 
2024-04-08 04:39:23.450517: Pseudo dice [0.8075] 
2024-04-08 04:39:23.450615: Epoch time: 8.97 s 
2024-04-08 04:39:23.450700: Yayy! New best EMA pseudo Dice: 0.7671 
2024-04-08 04:39:24.617314:  
2024-04-08 04:39:24.617412: Epoch 18 
2024-04-08 04:39:24.617493: Current learning rate: 0.00984 
2024-04-08 04:39:33.926468: train_loss -0.8459 
2024-04-08 04:39:33.926720: val_loss -0.7446 
2024-04-08 04:39:33.926849: Pseudo dice [0.7851] 
2024-04-08 04:39:33.926973: Epoch time: 9.31 s 
2024-04-08 04:39:33.927091: Yayy! New best EMA pseudo Dice: 0.7689 
2024-04-08 04:39:35.237696:  
2024-04-08 04:39:35.237816: Epoch 19 
2024-04-08 04:39:35.237895: Current learning rate: 0.00983 
2024-04-08 04:39:44.646798: train_loss -0.8426 
2024-04-08 04:39:44.646954: val_loss -0.7591 
2024-04-08 04:39:44.647017: Pseudo dice [0.7964] 
2024-04-08 04:39:44.647075: Epoch time: 9.41 s 
2024-04-08 04:39:44.647123: Yayy! New best EMA pseudo Dice: 0.7717 
2024-04-08 04:39:45.755955:  
2024-04-08 04:39:45.756054: Epoch 20 
2024-04-08 04:39:45.756150: Current learning rate: 0.00982 
2024-04-08 04:39:55.017743: train_loss -0.8439 
2024-04-08 04:39:55.017903: val_loss -0.7497 
2024-04-08 04:39:55.017966: Pseudo dice [0.797] 
2024-04-08 04:39:55.018026: Epoch time: 9.26 s 
2024-04-08 04:39:55.018100: Yayy! New best EMA pseudo Dice: 0.7742 
2024-04-08 04:39:56.200975:  
2024-04-08 04:39:56.201076: Epoch 21 
2024-04-08 04:39:56.201157: Current learning rate: 0.00981 
2024-04-08 04:40:05.060748: train_loss -0.8496 
2024-04-08 04:40:05.060942: val_loss -0.7524 
2024-04-08 04:40:05.061052: Pseudo dice [0.7954] 
2024-04-08 04:40:05.061112: Epoch time: 8.86 s 
2024-04-08 04:40:05.061162: Yayy! New best EMA pseudo Dice: 0.7763 
2024-04-08 04:40:06.199003:  
2024-04-08 04:40:06.199117: Epoch 22 
2024-04-08 04:40:06.199200: Current learning rate: 0.0098 
2024-04-08 04:40:15.271876: train_loss -0.8558 
2024-04-08 04:40:15.272021: val_loss -0.7721 
2024-04-08 04:40:15.272083: Pseudo dice [0.8118] 
2024-04-08 04:40:15.272156: Epoch time: 9.07 s 
2024-04-08 04:40:15.272207: Yayy! New best EMA pseudo Dice: 0.7799 
2024-04-08 04:40:16.382258:  
2024-04-08 04:40:16.382370: Epoch 23 
2024-04-08 04:40:16.382463: Current learning rate: 0.00979 
2024-04-08 04:40:25.987652: train_loss -0.8569 
2024-04-08 04:40:25.987891: val_loss -0.7587 
2024-04-08 04:40:25.988082: Pseudo dice [0.7999] 
2024-04-08 04:40:25.988343: Epoch time: 9.61 s 
2024-04-08 04:40:25.988424: Yayy! New best EMA pseudo Dice: 0.7819 
2024-04-08 04:40:27.125479:  
2024-04-08 04:40:27.125582: Epoch 24 
2024-04-08 04:40:27.125661: Current learning rate: 0.00978 
2024-04-08 04:40:36.314580: train_loss -0.8607 
2024-04-08 04:40:36.314725: val_loss -0.775 
2024-04-08 04:40:36.314788: Pseudo dice [0.8203] 
2024-04-08 04:40:36.315022: Epoch time: 9.19 s 
2024-04-08 04:40:36.315207: Yayy! New best EMA pseudo Dice: 0.7857 
2024-04-08 04:40:37.455471:  
2024-04-08 04:40:37.455658: Epoch 25 
2024-04-08 04:40:37.455748: Current learning rate: 0.00977 
2024-04-08 04:40:46.630950: train_loss -0.8634 
2024-04-08 04:40:46.631161: val_loss -0.7626 
2024-04-08 04:40:46.631349: Pseudo dice [0.8019] 
2024-04-08 04:40:46.631491: Epoch time: 9.18 s 
2024-04-08 04:40:46.631685: Yayy! New best EMA pseudo Dice: 0.7873 
2024-04-08 04:40:47.774878:  
2024-04-08 04:40:47.774996: Epoch 26 
2024-04-08 04:40:47.775092: Current learning rate: 0.00977 
2024-04-08 04:40:56.926102: train_loss -0.864 
2024-04-08 04:40:56.926274: val_loss -0.7797 
2024-04-08 04:40:56.934699: Pseudo dice [0.8202] 
2024-04-08 04:40:56.934903: Epoch time: 9.15 s 
2024-04-08 04:40:56.935059: Yayy! New best EMA pseudo Dice: 0.7906 
2024-04-08 04:40:58.089867:  
2024-04-08 04:40:58.089982: Epoch 27 
2024-04-08 04:40:58.090063: Current learning rate: 0.00976 
2024-04-08 04:41:07.520236: train_loss -0.8691 
2024-04-08 04:41:07.520396: val_loss -0.8011 
2024-04-08 04:41:07.520467: Pseudo dice [0.8352] 
2024-04-08 04:41:07.520546: Epoch time: 9.43 s 
2024-04-08 04:41:07.520597: Yayy! New best EMA pseudo Dice: 0.7951 
2024-04-08 04:41:08.730357:  
2024-04-08 04:41:08.730462: Epoch 28 
2024-04-08 04:41:08.730541: Current learning rate: 0.00975 
2024-04-08 04:41:17.752445: train_loss -0.8723 
2024-04-08 04:41:17.752800: val_loss -0.7805 
2024-04-08 04:41:17.752926: Pseudo dice [0.8168] 
2024-04-08 04:41:17.753103: Epoch time: 9.02 s 
2024-04-08 04:41:17.753289: Yayy! New best EMA pseudo Dice: 0.7972 
2024-04-08 04:41:18.895178:  
2024-04-08 04:41:18.895297: Epoch 29 
2024-04-08 04:41:18.895377: Current learning rate: 0.00974 
2024-04-08 04:41:28.138507: train_loss -0.8686 
2024-04-08 04:41:28.138660: val_loss -0.7678 
2024-04-08 04:41:28.138725: Pseudo dice [0.8089] 
2024-04-08 04:41:28.138792: Epoch time: 9.24 s 
2024-04-08 04:41:28.138842: Yayy! New best EMA pseudo Dice: 0.7984 
2024-04-08 04:41:29.269495:  
2024-04-08 04:41:29.269610: Epoch 30 
2024-04-08 04:41:29.269745: Current learning rate: 0.00973 
2024-04-08 04:41:38.165727: train_loss -0.8755 
2024-04-08 04:41:38.165867: val_loss -0.7717 
2024-04-08 04:41:38.165943: Pseudo dice [0.8141] 
2024-04-08 04:41:38.166000: Epoch time: 8.9 s 
2024-04-08 04:41:38.166046: Yayy! New best EMA pseudo Dice: 0.8 
2024-04-08 04:41:39.302068:  
2024-04-08 04:41:39.302180: Epoch 31 
2024-04-08 04:41:39.302277: Current learning rate: 0.00972 
2024-04-08 04:41:48.446718: train_loss -0.8769 
2024-04-08 04:41:48.446856: val_loss -0.7753 
2024-04-08 04:41:48.446915: Pseudo dice [0.8146] 
2024-04-08 04:41:48.446970: Epoch time: 9.15 s 
2024-04-08 04:41:48.447015: Yayy! New best EMA pseudo Dice: 0.8014 
2024-04-08 04:41:49.550540:  
2024-04-08 04:41:49.550663: Epoch 32 
2024-04-08 04:41:49.550758: Current learning rate: 0.00971 
2024-04-08 04:41:58.856766: train_loss -0.8751 
2024-04-08 04:41:58.856918: val_loss -0.764 
2024-04-08 04:41:58.856991: Pseudo dice [0.8028] 
2024-04-08 04:41:58.857059: Epoch time: 9.31 s 
2024-04-08 04:41:58.857118: Yayy! New best EMA pseudo Dice: 0.8016 
2024-04-08 04:42:00.114617:  
2024-04-08 04:42:00.114726: Epoch 33 
2024-04-08 04:42:00.114825: Current learning rate: 0.0097 
2024-04-08 04:42:09.074000: train_loss -0.8773 
2024-04-08 04:42:09.074149: val_loss -0.7674 
2024-04-08 04:42:09.074212: Pseudo dice [0.819] 
2024-04-08 04:42:09.074271: Epoch time: 8.96 s 
2024-04-08 04:42:09.074320: Yayy! New best EMA pseudo Dice: 0.8033 
2024-04-08 04:42:10.257816:  
2024-04-08 04:42:10.257921: Epoch 34 
2024-04-08 04:42:10.258016: Current learning rate: 0.00969 
2024-04-08 04:42:19.750701: train_loss -0.8781 
2024-04-08 04:42:19.751384: val_loss -0.7623 
2024-04-08 04:42:19.751659: Pseudo dice [0.8113] 
2024-04-08 04:42:19.751910: Epoch time: 9.49 s 
2024-04-08 04:42:19.752274: Yayy! New best EMA pseudo Dice: 0.8041 
2024-04-08 04:42:20.898895:  
2024-04-08 04:42:20.898995: Epoch 35 
2024-04-08 04:42:20.899107: Current learning rate: 0.00968 
2024-04-08 04:42:29.809821: train_loss -0.8815 
2024-04-08 04:42:29.809960: val_loss -0.7447 
2024-04-08 04:42:29.810038: Pseudo dice [0.7956] 
2024-04-08 04:42:29.810096: Epoch time: 8.91 s 
2024-04-08 04:42:30.812939:  
2024-04-08 04:42:30.813038: Epoch 36 
2024-04-08 04:42:30.813116: Current learning rate: 0.00968 
2024-04-08 04:42:40.341366: train_loss -0.8776 
2024-04-08 04:42:40.341509: val_loss -0.7434 
2024-04-08 04:42:40.341572: Pseudo dice [0.7883] 
2024-04-08 04:42:40.341640: Epoch time: 9.53 s 
2024-04-08 04:42:41.383595:  
2024-04-08 04:42:41.383690: Epoch 37 
2024-04-08 04:42:41.383766: Current learning rate: 0.00967 
2024-04-08 04:42:50.292625: train_loss -0.8817 
2024-04-08 04:42:50.292781: val_loss -0.7572 
2024-04-08 04:42:50.292866: Pseudo dice [0.8009] 
2024-04-08 04:42:50.292945: Epoch time: 8.91 s 
2024-04-08 04:42:51.468609:  
2024-04-08 04:42:51.468737: Epoch 38 
2024-04-08 04:42:51.468817: Current learning rate: 0.00966 
2024-04-08 04:43:00.761774: train_loss -0.8878 
2024-04-08 04:43:00.761995: val_loss -0.7765 
2024-04-08 04:43:00.762101: Pseudo dice [0.8164] 
2024-04-08 04:43:00.762205: Epoch time: 9.29 s 
2024-04-08 04:43:01.830919:  
2024-04-08 04:43:01.831019: Epoch 39 
2024-04-08 04:43:01.831115: Current learning rate: 0.00965 
2024-04-08 04:43:10.729183: train_loss -0.8886 
2024-04-08 04:43:10.729381: val_loss -0.7747 
2024-04-08 04:43:10.729499: Pseudo dice [0.8163] 
2024-04-08 04:43:10.729563: Epoch time: 8.9 s 
2024-04-08 04:43:10.729746: Yayy! New best EMA pseudo Dice: 0.8045 
2024-04-08 04:43:11.893295:  
2024-04-08 04:43:11.893399: Epoch 40 
2024-04-08 04:43:11.893479: Current learning rate: 0.00964 
2024-04-08 04:43:20.968287: train_loss -0.8903 
2024-04-08 04:43:20.968425: val_loss -0.7582 
2024-04-08 04:43:20.968530: Pseudo dice [0.8106] 
2024-04-08 04:43:20.968592: Epoch time: 9.08 s 
2024-04-08 04:43:20.968642: Yayy! New best EMA pseudo Dice: 0.8051 
2024-04-08 04:43:22.195595:  
2024-04-08 04:43:22.195709: Epoch 41 
2024-04-08 04:43:22.195787: Current learning rate: 0.00963 
2024-04-08 04:43:31.322913: train_loss -0.8939 
2024-04-08 04:43:31.323055: val_loss -0.769 
2024-04-08 04:43:31.323146: Pseudo dice [0.8088] 
2024-04-08 04:43:31.323248: Epoch time: 9.13 s 
2024-04-08 04:43:31.323300: Yayy! New best EMA pseudo Dice: 0.8054 
2024-04-08 04:43:32.405903:  
2024-04-08 04:43:32.405997: Epoch 42 
2024-04-08 04:43:32.406079: Current learning rate: 0.00962 
2024-04-08 04:43:41.736945: train_loss -0.8884 
2024-04-08 04:43:41.737136: val_loss -0.7834 
2024-04-08 04:43:41.737230: Pseudo dice [0.8266] 
2024-04-08 04:43:41.737320: Epoch time: 9.33 s 
2024-04-08 04:43:41.737396: Yayy! New best EMA pseudo Dice: 0.8076 
2024-04-08 04:43:42.950519:  
2024-04-08 04:43:42.950638: Epoch 43 
2024-04-08 04:43:42.950732: Current learning rate: 0.00961 
2024-04-08 04:43:52.079110: train_loss -0.8886 
2024-04-08 04:43:52.079472: val_loss -0.7808 
2024-04-08 04:43:52.079571: Pseudo dice [0.8275] 
2024-04-08 04:43:52.079663: Epoch time: 9.13 s 
2024-04-08 04:43:52.079726: Yayy! New best EMA pseudo Dice: 0.8096 
2024-04-08 04:43:53.266017:  
2024-04-08 04:43:53.266142: Epoch 44 
2024-04-08 04:43:53.266225: Current learning rate: 0.0096 
2024-04-08 04:44:02.569222: train_loss -0.8928 
2024-04-08 04:44:02.569536: val_loss -0.7672 
2024-04-08 04:44:02.569603: Pseudo dice [0.8052] 
2024-04-08 04:44:02.569664: Epoch time: 9.3 s 
2024-04-08 04:44:03.552644:  
2024-04-08 04:44:03.552741: Epoch 45 
2024-04-08 04:44:03.552821: Current learning rate: 0.00959 
2024-04-08 04:44:12.758916: train_loss -0.8881 
2024-04-08 04:44:12.759257: val_loss -0.7814 
2024-04-08 04:44:12.759743: Pseudo dice [0.821] 
2024-04-08 04:44:12.759803: Epoch time: 9.21 s 
2024-04-08 04:44:12.759928: Yayy! New best EMA pseudo Dice: 0.8103 
2024-04-08 04:44:13.882540:  
2024-04-08 04:44:13.882642: Epoch 46 
2024-04-08 04:44:13.882738: Current learning rate: 0.00959 
2024-04-08 04:44:23.158940: train_loss -0.9002 
2024-04-08 04:44:23.159158: val_loss -0.7756 
2024-04-08 04:44:23.159221: Pseudo dice [0.8223] 
2024-04-08 04:44:23.159354: Epoch time: 9.28 s 
2024-04-08 04:44:23.159425: Yayy! New best EMA pseudo Dice: 0.8115 
2024-04-08 04:44:24.280564:  
2024-04-08 04:44:24.280661: Epoch 47 
2024-04-08 04:44:24.280740: Current learning rate: 0.00958 
2024-04-08 04:44:33.615423: train_loss -0.8938 
2024-04-08 04:44:33.615622: val_loss -0.7561 
2024-04-08 04:44:33.615691: Pseudo dice [0.7965] 
2024-04-08 04:44:33.615884: Epoch time: 9.34 s 
2024-04-08 04:44:34.779034:  
2024-04-08 04:44:34.779139: Epoch 48 
2024-04-08 04:44:34.779239: Current learning rate: 0.00957 
2024-04-08 04:44:44.280723: train_loss -0.8945 
2024-04-08 04:44:44.280870: val_loss -0.7634 
2024-04-08 04:44:44.280934: Pseudo dice [0.8056] 
2024-04-08 04:44:44.281011: Epoch time: 9.5 s 
2024-04-08 04:44:45.239490:  
2024-04-08 04:44:45.239588: Epoch 49 
2024-04-08 04:44:45.239694: Current learning rate: 0.00956 
2024-04-08 04:44:54.425919: train_loss -0.8944 
2024-04-08 04:44:54.426168: val_loss -0.7731 
2024-04-08 04:44:54.426254: Pseudo dice [0.8165] 
2024-04-08 04:44:54.426389: Epoch time: 9.19 s 
2024-04-08 04:44:55.450687:  
2024-04-08 04:44:55.450809: Epoch 50 
2024-04-08 04:44:55.450891: Current learning rate: 0.00955 
2024-04-08 04:45:04.638371: train_loss -0.898 
2024-04-08 04:45:04.638521: val_loss -0.7743 
2024-04-08 04:45:04.638583: Pseudo dice [0.8145] 
2024-04-08 04:45:04.638643: Epoch time: 9.19 s 
2024-04-08 04:45:05.637300:  
2024-04-08 04:45:05.637399: Epoch 51 
2024-04-08 04:45:05.637478: Current learning rate: 0.00954 
2024-04-08 04:45:14.899284: train_loss -0.8998 
2024-04-08 04:45:14.899424: val_loss -0.7708 
2024-04-08 04:45:14.899500: Pseudo dice [0.8142] 
2024-04-08 04:45:14.899559: Epoch time: 9.26 s 
2024-04-08 04:45:15.851768:  
2024-04-08 04:45:15.851867: Epoch 52 
2024-04-08 04:45:15.851962: Current learning rate: 0.00953 
2024-04-08 04:45:25.034689: train_loss -0.9015 
2024-04-08 04:45:25.034970: val_loss -0.7642 
2024-04-08 04:45:25.035126: Pseudo dice [0.8113] 
2024-04-08 04:45:25.035292: Epoch time: 9.18 s 
2024-04-08 04:45:26.181090:  
2024-04-08 04:45:26.181190: Epoch 53 
2024-04-08 04:45:26.181273: Current learning rate: 0.00952 
2024-04-08 04:45:34.988451: train_loss -0.9014 
2024-04-08 04:45:34.988668: val_loss -0.78 
2024-04-08 04:45:34.988773: Pseudo dice [0.8173] 
2024-04-08 04:45:34.988873: Epoch time: 8.81 s 
2024-04-08 04:45:34.988958: Yayy! New best EMA pseudo Dice: 0.8117 
2024-04-08 04:45:36.112569:  
2024-04-08 04:45:36.112688: Epoch 54 
2024-04-08 04:45:36.112774: Current learning rate: 0.00951 
2024-04-08 04:45:45.283020: train_loss -0.9022 
2024-04-08 04:45:45.283236: val_loss -0.7706 
2024-04-08 04:45:45.283433: Pseudo dice [0.8136] 
2024-04-08 04:45:45.283498: Epoch time: 9.17 s 
2024-04-08 04:45:45.283723: Yayy! New best EMA pseudo Dice: 0.8119 
2024-04-08 04:45:46.383868:  
2024-04-08 04:45:46.383982: Epoch 55 
2024-04-08 04:45:46.384085: Current learning rate: 0.0095 
2024-04-08 04:45:55.385483: train_loss -0.8994 
2024-04-08 04:45:55.385636: val_loss -0.7838 
2024-04-08 04:45:55.385723: Pseudo dice [0.8185] 
2024-04-08 04:45:55.385794: Epoch time: 9.0 s 
2024-04-08 04:45:55.385843: Yayy! New best EMA pseudo Dice: 0.8125 
2024-04-08 04:45:56.591643:  
2024-04-08 04:45:56.591829: Epoch 56 
2024-04-08 04:45:56.591912: Current learning rate: 0.00949 
2024-04-08 04:46:05.971692: train_loss -0.9025 
2024-04-08 04:46:05.971869: val_loss -0.7813 
2024-04-08 04:46:05.971949: Pseudo dice [0.8206] 
2024-04-08 04:46:05.972025: Epoch time: 9.38 s 
2024-04-08 04:46:05.972088: Yayy! New best EMA pseudo Dice: 0.8133 
2024-04-08 04:46:07.076306:  
2024-04-08 04:46:07.076647: Epoch 57 
2024-04-08 04:46:07.076905: Current learning rate: 0.00949 
2024-04-08 04:46:16.302821: train_loss -0.9035 
2024-04-08 04:46:16.303161: val_loss -0.7716 
2024-04-08 04:46:16.303283: Pseudo dice [0.8101] 
2024-04-08 04:46:16.303510: Epoch time: 9.23 s 
2024-04-08 04:46:17.330875:  
2024-04-08 04:46:17.330972: Epoch 58 
2024-04-08 04:46:17.331050: Current learning rate: 0.00948 
2024-04-08 04:46:26.666677: train_loss -0.8991 
2024-04-08 04:46:26.667067: val_loss -0.7953 
2024-04-08 04:46:26.667140: Pseudo dice [0.8319] 
2024-04-08 04:46:26.667197: Epoch time: 9.34 s 
2024-04-08 04:46:26.667244: Yayy! New best EMA pseudo Dice: 0.8149 
2024-04-08 04:46:27.927584:  
2024-04-08 04:46:27.927696: Epoch 59 
2024-04-08 04:46:27.927809: Current learning rate: 0.00947 
2024-04-08 04:46:37.311026: train_loss -0.9054 
2024-04-08 04:46:37.311233: val_loss -0.7957 
2024-04-08 04:46:37.311294: Pseudo dice [0.8329] 
2024-04-08 04:46:37.311349: Epoch time: 9.38 s 
2024-04-08 04:46:37.311470: Yayy! New best EMA pseudo Dice: 0.8167 
2024-04-08 04:46:38.465773:  
2024-04-08 04:46:38.466109: Epoch 60 
2024-04-08 04:46:38.466193: Current learning rate: 0.00946 
2024-04-08 04:46:47.223582: train_loss -0.9043 
2024-04-08 04:46:47.223798: val_loss -0.7741 
2024-04-08 04:46:47.223904: Pseudo dice [0.8186] 
2024-04-08 04:46:47.224007: Epoch time: 8.76 s 
2024-04-08 04:46:47.224095: Yayy! New best EMA pseudo Dice: 0.8169 
2024-04-08 04:46:48.320343:  
2024-04-08 04:46:48.320452: Epoch 61 
2024-04-08 04:46:48.320536: Current learning rate: 0.00945 
2024-04-08 04:46:57.110376: train_loss -0.9039 
2024-04-08 04:46:57.110535: val_loss -0.7747 
2024-04-08 04:46:57.110600: Pseudo dice [0.8157] 
2024-04-08 04:46:57.110824: Epoch time: 8.79 s 
2024-04-08 04:46:58.094010:  
2024-04-08 04:46:58.094209: Epoch 62 
2024-04-08 04:46:58.094292: Current learning rate: 0.00944 
2024-04-08 04:47:07.362411: train_loss -0.9072 
2024-04-08 04:47:07.362766: val_loss -0.7849 
2024-04-08 04:47:07.362938: Pseudo dice [0.8244] 
2024-04-08 04:47:07.363044: Epoch time: 9.27 s 
2024-04-08 04:47:07.363090: Yayy! New best EMA pseudo Dice: 0.8175 
2024-04-08 04:47:08.507130:  
2024-04-08 04:47:08.507246: Epoch 63 
2024-04-08 04:47:08.507328: Current learning rate: 0.00943 
2024-04-08 04:47:18.267515: train_loss -0.9092 
2024-04-08 04:47:18.267776: val_loss -0.7719 
2024-04-08 04:47:18.267940: Pseudo dice [0.8157] 
2024-04-08 04:47:18.268095: Epoch time: 9.76 s 
2024-04-08 04:47:19.287282:  
2024-04-08 04:47:19.287387: Epoch 64 
2024-04-08 04:47:19.287466: Current learning rate: 0.00942 
2024-04-08 04:47:28.507985: train_loss -0.9047 
2024-04-08 04:47:28.508144: val_loss -0.7904 
2024-04-08 04:47:28.508207: Pseudo dice [0.8275] 
2024-04-08 04:47:28.508262: Epoch time: 9.22 s 
2024-04-08 04:47:28.508309: Yayy! New best EMA pseudo Dice: 0.8184 
2024-04-08 04:47:29.622729:  
2024-04-08 04:47:29.622960: Epoch 65 
2024-04-08 04:47:29.623045: Current learning rate: 0.00941 
2024-04-08 04:47:38.865546: train_loss -0.9089 
2024-04-08 04:47:38.865706: val_loss -0.7655 
2024-04-08 04:47:38.865769: Pseudo dice [0.8122] 
2024-04-08 04:47:38.865829: Epoch time: 9.24 s 
2024-04-08 04:47:39.887050:  
2024-04-08 04:47:39.887285: Epoch 66 
2024-04-08 04:47:39.887368: Current learning rate: 0.0094 
2024-04-08 04:47:49.115982: train_loss -0.9129 
2024-04-08 04:47:49.116188: val_loss -0.7844 
2024-04-08 04:47:49.116279: Pseudo dice [0.8242] 
2024-04-08 04:47:49.116414: Epoch time: 9.23 s 
2024-04-08 04:47:49.116538: Yayy! New best EMA pseudo Dice: 0.8184 
2024-04-08 04:47:50.212783:  
2024-04-08 04:47:50.212882: Epoch 67 
2024-04-08 04:47:50.212960: Current learning rate: 0.00939 
2024-04-08 04:47:59.391777: train_loss -0.9119 
2024-04-08 04:47:59.392054: val_loss -0.7615 
2024-04-08 04:47:59.392206: Pseudo dice [0.8096] 
2024-04-08 04:47:59.392372: Epoch time: 9.18 s 
2024-04-08 04:48:00.414165:  
2024-04-08 04:48:00.414279: Epoch 68 
2024-04-08 04:48:00.414359: Current learning rate: 0.00939 
2024-04-08 04:48:09.858536: train_loss -0.9098 
2024-04-08 04:48:09.858687: val_loss -0.7642 
2024-04-08 04:48:09.858763: Pseudo dice [0.8142] 
2024-04-08 04:48:09.858823: Epoch time: 9.45 s 
2024-04-08 04:48:11.014489:  
2024-04-08 04:48:11.014591: Epoch 69 
2024-04-08 04:48:11.014689: Current learning rate: 0.00938 
2024-04-08 04:48:20.472142: train_loss -0.9122 
2024-04-08 04:48:20.472461: val_loss -0.7688 
2024-04-08 04:48:20.472688: Pseudo dice [0.8118] 
2024-04-08 04:48:20.472845: Epoch time: 9.46 s 
2024-04-08 04:48:21.530974:  
2024-04-08 04:48:21.531076: Epoch 70 
2024-04-08 04:48:21.531156: Current learning rate: 0.00937 
2024-04-08 04:48:30.891015: train_loss -0.913 
2024-04-08 04:48:30.891472: val_loss -0.7735 
2024-04-08 04:48:30.891584: Pseudo dice [0.8126] 
2024-04-08 04:48:30.891653: Epoch time: 9.36 s 
2024-04-08 04:48:31.889509:  
2024-04-08 04:48:31.889626: Epoch 71 
2024-04-08 04:48:31.889705: Current learning rate: 0.00936 
2024-04-08 04:48:41.467808: train_loss -0.9131 
2024-04-08 04:48:41.467949: val_loss -0.7603 
2024-04-08 04:48:41.468007: Pseudo dice [0.8071] 
2024-04-08 04:48:41.468062: Epoch time: 9.58 s 
2024-04-08 04:48:42.504284:  
2024-04-08 04:48:42.504408: Epoch 72 
2024-04-08 04:48:42.504499: Current learning rate: 0.00935 
2024-04-08 04:48:51.885308: train_loss -0.9116 
2024-04-08 04:48:51.885452: val_loss -0.794 
2024-04-08 04:48:51.885680: Pseudo dice [0.8313] 
2024-04-08 04:48:51.885809: Epoch time: 9.38 s 
2024-04-08 04:48:52.889714:  
2024-04-08 04:48:52.889812: Epoch 73 
2024-04-08 04:48:52.889893: Current learning rate: 0.00934 
2024-04-08 04:49:02.175319: train_loss -0.9124 
2024-04-08 04:49:02.175543: val_loss -0.7776 
2024-04-08 04:49:02.176230: Pseudo dice [0.8217] 
2024-04-08 04:49:02.176324: Epoch time: 9.29 s 
2024-04-08 04:49:03.348330:  
2024-04-08 04:49:03.348439: Epoch 74 
2024-04-08 04:49:03.348536: Current learning rate: 0.00933 
2024-04-08 04:49:12.794684: train_loss -0.9127 
2024-04-08 04:49:12.794831: val_loss -0.7787 
2024-04-08 04:49:12.794894: Pseudo dice [0.8275] 
2024-04-08 04:49:12.794954: Epoch time: 9.45 s 
2024-04-08 04:49:12.795003: Yayy! New best EMA pseudo Dice: 0.8184 
2024-04-08 04:49:13.933304:  
2024-04-08 04:49:13.933492: Epoch 75 
2024-04-08 04:49:13.933578: Current learning rate: 0.00932 
2024-04-08 04:49:23.091884: train_loss -0.9167 
2024-04-08 04:49:23.092110: val_loss -0.773 
2024-04-08 04:49:23.092210: Pseudo dice [0.8144] 
2024-04-08 04:49:23.092367: Epoch time: 9.16 s 
2024-04-08 04:49:24.155356:  
2024-04-08 04:49:24.155593: Epoch 76 
2024-04-08 04:49:24.155677: Current learning rate: 0.00931 
2024-04-08 04:49:33.296978: train_loss -0.9147 
2024-04-08 04:49:33.297302: val_loss -0.7648 
2024-04-08 04:49:33.297371: Pseudo dice [0.8071] 
2024-04-08 04:49:33.297433: Epoch time: 9.14 s 
2024-04-08 04:49:34.302237:  
2024-04-08 04:49:34.302336: Epoch 77 
2024-04-08 04:49:34.302430: Current learning rate: 0.0093 
2024-04-08 04:49:43.699214: train_loss -0.918 
2024-04-08 04:49:43.699435: val_loss -0.7804 
2024-04-08 04:49:43.699553: Pseudo dice [0.8177] 
2024-04-08 04:49:43.699636: Epoch time: 9.4 s 
2024-04-08 04:49:44.718438:  
2024-04-08 04:49:44.718539: Epoch 78 
2024-04-08 04:49:44.718635: Current learning rate: 0.0093 
2024-04-08 04:49:54.126507: train_loss -0.9097 
2024-04-08 04:49:54.126970: val_loss -0.7848 
2024-04-08 04:49:54.127192: Pseudo dice [0.8208] 
2024-04-08 04:49:54.127393: Epoch time: 9.41 s 
2024-04-08 04:49:55.417731:  
2024-04-08 04:49:55.417832: Epoch 79 
2024-04-08 04:49:55.417912: Current learning rate: 0.00929 
2024-04-08 04:50:04.371911: train_loss -0.9034 
2024-04-08 04:50:04.372052: val_loss -0.7643 
2024-04-08 04:50:04.372127: Pseudo dice [0.8059] 
2024-04-08 04:50:04.372186: Epoch time: 8.95 s 
2024-04-08 04:50:05.385488:  
2024-04-08 04:50:05.385595: Epoch 80 
2024-04-08 04:50:05.385694: Current learning rate: 0.00928 
2024-04-08 04:50:14.434854: train_loss -0.9138 
2024-04-08 04:50:14.435175: val_loss -0.7817 
2024-04-08 04:50:14.435268: Pseudo dice [0.8218] 
2024-04-08 04:50:14.435330: Epoch time: 9.05 s 
2024-04-08 04:50:15.478138:  
2024-04-08 04:50:15.478262: Epoch 81 
2024-04-08 04:50:15.478344: Current learning rate: 0.00927 
2024-04-08 04:50:24.474261: train_loss -0.9159 
2024-04-08 04:50:24.474450: val_loss -0.7802 
2024-04-08 04:50:24.474607: Pseudo dice [0.818] 
2024-04-08 04:50:24.474694: Epoch time: 9.0 s 
2024-04-08 04:50:25.525471:  
2024-04-08 04:50:25.525572: Epoch 82 
2024-04-08 04:50:25.525653: Current learning rate: 0.00926 
2024-04-08 04:50:34.462328: train_loss -0.916 
2024-04-08 04:50:34.462553: val_loss -0.7806 
2024-04-08 04:50:34.462632: Pseudo dice [0.8262] 
2024-04-08 04:50:34.462745: Epoch time: 8.94 s 
2024-04-08 04:50:35.424568:  
2024-04-08 04:50:35.424664: Epoch 83 
2024-04-08 04:50:35.424742: Current learning rate: 0.00925 
2024-04-08 04:50:44.495297: train_loss -0.9156 
2024-04-08 04:50:44.495437: val_loss -0.7725 
2024-04-08 04:50:44.495497: Pseudo dice [0.814] 
2024-04-08 04:50:44.495552: Epoch time: 9.07 s 
2024-04-08 04:50:45.600507:  
2024-04-08 04:50:45.600617: Epoch 84 
2024-04-08 04:50:45.600698: Current learning rate: 0.00924 
2024-04-08 04:50:54.854606: train_loss -0.9131 
2024-04-08 04:50:54.854744: val_loss -0.7833 
2024-04-08 04:50:54.854820: Pseudo dice [0.8227] 
2024-04-08 04:50:54.854879: Epoch time: 9.25 s 
2024-04-08 04:50:55.801408:  
2024-04-08 04:50:55.801511: Epoch 85 
2024-04-08 04:50:55.801592: Current learning rate: 0.00923 
2024-04-08 04:51:04.457882: train_loss -0.915 
2024-04-08 04:51:04.458028: val_loss -0.7814 
2024-04-08 04:51:04.458103: Pseudo dice [0.8187] 
2024-04-08 04:51:04.458163: Epoch time: 8.66 s 
2024-04-08 04:51:05.558156:  
2024-04-08 04:51:05.558258: Epoch 86 
2024-04-08 04:51:05.558351: Current learning rate: 0.00922 
2024-04-08 04:51:14.838241: train_loss -0.9154 
2024-04-08 04:51:14.838562: val_loss -0.7673 
2024-04-08 04:51:14.838628: Pseudo dice [0.8154] 
2024-04-08 04:51:14.838780: Epoch time: 9.28 s 
2024-04-08 04:51:15.821620:  
2024-04-08 04:51:15.821727: Epoch 87 
2024-04-08 04:51:15.821822: Current learning rate: 0.00921 
2024-04-08 04:51:24.615233: train_loss -0.9165 
2024-04-08 04:51:24.615489: val_loss -0.7882 
2024-04-08 04:51:24.615620: Pseudo dice [0.8271] 
2024-04-08 04:51:24.615744: Epoch time: 8.79 s 
2024-04-08 04:51:24.615850: Yayy! New best EMA pseudo Dice: 0.8187 
2024-04-08 04:51:25.698177:  
2024-04-08 04:51:25.698402: Epoch 88 
2024-04-08 04:51:25.698489: Current learning rate: 0.0092 
2024-04-08 04:51:34.923533: train_loss -0.92 
2024-04-08 04:51:34.923668: val_loss -0.78 
2024-04-08 04:51:34.923726: Pseudo dice [0.8233] 
2024-04-08 04:51:34.923781: Epoch time: 9.23 s 
2024-04-08 04:51:34.923826: Yayy! New best EMA pseudo Dice: 0.8192 
2024-04-08 04:51:36.144719:  
2024-04-08 04:51:36.144821: Epoch 89 
2024-04-08 04:51:36.144900: Current learning rate: 0.0092 
2024-04-08 04:51:45.754852: train_loss -0.9225 
2024-04-08 04:51:45.755006: val_loss -0.7843 
2024-04-08 04:51:45.755069: Pseudo dice [0.8287] 
2024-04-08 04:51:45.755129: Epoch time: 9.61 s 
2024-04-08 04:51:45.755192: Yayy! New best EMA pseudo Dice: 0.8201 
2024-04-08 04:51:46.870804:  
2024-04-08 04:51:46.870908: Epoch 90 
2024-04-08 04:51:46.871020: Current learning rate: 0.00919 
2024-04-08 04:51:55.945434: train_loss -0.9218 
2024-04-08 04:51:55.945577: val_loss -0.7674 
2024-04-08 04:51:55.945935: Pseudo dice [0.8103] 
2024-04-08 04:51:55.946160: Epoch time: 9.08 s 
2024-04-08 04:51:56.897129:  
2024-04-08 04:51:56.897230: Epoch 91 
2024-04-08 04:51:56.897311: Current learning rate: 0.00918 
2024-04-08 04:52:05.954768: train_loss -0.9192 
2024-04-08 04:52:05.955120: val_loss -0.7727 
2024-04-08 04:52:05.955313: Pseudo dice [0.8188] 
2024-04-08 04:52:05.955436: Epoch time: 9.06 s 
2024-04-08 04:52:06.921778:  
2024-04-08 04:52:06.921872: Epoch 92 
2024-04-08 04:52:06.921968: Current learning rate: 0.00917 
2024-04-08 04:52:15.967212: train_loss -0.913 
2024-04-08 04:52:15.967455: val_loss -0.7826 
2024-04-08 04:52:15.967691: Pseudo dice [0.8253] 
2024-04-08 04:52:15.968169: Epoch time: 9.05 s 
2024-04-08 04:52:16.948565:  
2024-04-08 04:52:16.948659: Epoch 93 
2024-04-08 04:52:16.948737: Current learning rate: 0.00916 
2024-04-08 04:52:26.278995: train_loss -0.914 
2024-04-08 04:52:26.279206: val_loss -0.7667 
2024-04-08 04:52:26.279270: Pseudo dice [0.812] 
2024-04-08 04:52:26.279329: Epoch time: 9.33 s 
2024-04-08 04:52:27.395761:  
2024-04-08 04:52:27.395862: Epoch 94 
2024-04-08 04:52:27.395958: Current learning rate: 0.00915 
2024-04-08 04:52:36.888816: train_loss -0.9187 
2024-04-08 04:52:36.888970: val_loss -0.7721 
2024-04-08 04:52:36.889034: Pseudo dice [0.8164] 
2024-04-08 04:52:36.889092: Epoch time: 9.49 s 
2024-04-08 04:52:37.861577:  
2024-04-08 04:52:37.861680: Epoch 95 
2024-04-08 04:52:37.861760: Current learning rate: 0.00914 
2024-04-08 04:52:47.061543: train_loss -0.9213 
2024-04-08 04:52:47.061694: val_loss -0.7795 
2024-04-08 04:52:47.061750: Pseudo dice [0.8243] 
2024-04-08 04:52:47.061805: Epoch time: 9.2 s 
2024-04-08 04:52:48.053738:  
2024-04-08 04:52:48.053854: Epoch 96 
2024-04-08 04:52:48.053950: Current learning rate: 0.00913 
2024-04-08 04:52:56.898478: train_loss -0.9208 
2024-04-08 04:52:56.898665: val_loss -0.7782 
2024-04-08 04:52:56.898729: Pseudo dice [0.8187] 
2024-04-08 04:52:56.898886: Epoch time: 8.85 s 
2024-04-08 04:52:57.907523:  
2024-04-08 04:52:57.907622: Epoch 97 
2024-04-08 04:52:57.907716: Current learning rate: 0.00912 
2024-04-08 04:53:06.768625: train_loss -0.9186 
2024-04-08 04:53:06.768765: val_loss -0.775 
2024-04-08 04:53:06.768825: Pseudo dice [0.8222] 
2024-04-08 04:53:06.768899: Epoch time: 8.86 s 
2024-04-08 04:53:07.765097:  
2024-04-08 04:53:07.765315: Epoch 98 
2024-04-08 04:53:07.765399: Current learning rate: 0.00911 
2024-04-08 04:53:17.353394: train_loss -0.9245 
2024-04-08 04:53:17.353621: val_loss -0.7629 
2024-04-08 04:53:17.353744: Pseudo dice [0.8063] 
2024-04-08 04:53:17.353861: Epoch time: 9.59 s 
2024-04-08 04:53:18.333773:  
2024-04-08 04:53:18.333868: Epoch 99 
2024-04-08 04:53:18.333979: Current learning rate: 0.0091 
2024-04-08 04:53:26.893597: train_loss -0.9263 
2024-04-08 04:53:26.893787: val_loss -0.7596 
2024-04-08 04:53:26.893981: Pseudo dice [0.8098] 
2024-04-08 04:53:26.894072: Epoch time: 8.56 s 
2024-04-08 04:53:28.183104:  
2024-04-08 04:53:28.183202: Epoch 100 
2024-04-08 04:53:28.183314: Current learning rate: 0.0091 
2024-04-08 04:53:37.270181: train_loss -0.9266 
2024-04-08 04:53:37.270434: val_loss -0.7731 
2024-04-08 04:53:37.270678: Pseudo dice [0.8144] 
2024-04-08 04:53:37.270837: Epoch time: 9.09 s 
2024-04-08 04:53:38.231630:  
2024-04-08 04:53:38.231731: Epoch 101 
2024-04-08 04:53:38.231808: Current learning rate: 0.00909 
2024-04-08 04:53:47.019574: train_loss -0.9241 
2024-04-08 04:53:47.020293: val_loss -0.7882 
2024-04-08 04:53:47.020394: Pseudo dice [0.8335] 
2024-04-08 04:53:47.020544: Epoch time: 8.79 s 
2024-04-08 04:53:48.032287:  
2024-04-08 04:53:48.032405: Epoch 102 
2024-04-08 04:53:48.032498: Current learning rate: 0.00908 
2024-04-08 04:53:57.452039: train_loss -0.9283 
2024-04-08 04:53:57.452217: val_loss -0.7766 
2024-04-08 04:53:57.452357: Pseudo dice [0.8148] 
2024-04-08 04:53:57.452416: Epoch time: 9.42 s 
2024-04-08 04:53:58.414476:  
2024-04-08 04:53:58.414579: Epoch 103 
2024-04-08 04:53:58.414656: Current learning rate: 0.00907 
2024-04-08 04:54:07.921917: train_loss -0.9258 
2024-04-08 04:54:07.922117: val_loss -0.7715 
2024-04-08 04:54:07.922219: Pseudo dice [0.817] 
2024-04-08 04:54:07.922316: Epoch time: 9.51 s 
2024-04-08 04:54:08.933330:  
2024-04-08 04:54:08.933429: Epoch 104 
2024-04-08 04:54:08.933508: Current learning rate: 0.00906 
2024-04-08 04:54:18.083593: train_loss -0.9239 
2024-04-08 04:54:18.083730: val_loss -0.773 
2024-04-08 04:54:18.083790: Pseudo dice [0.8211] 
2024-04-08 04:54:18.083846: Epoch time: 9.15 s 
2024-04-08 04:54:19.246864:  
2024-04-08 04:54:19.247082: Epoch 105 
2024-04-08 04:54:19.247171: Current learning rate: 0.00905 
2024-04-08 04:54:28.671935: train_loss -0.9289 
2024-04-08 04:54:28.672138: val_loss -0.7774 
2024-04-08 04:54:28.672257: Pseudo dice [0.8157] 
2024-04-08 04:54:28.672355: Epoch time: 9.43 s 
2024-04-08 04:54:29.688402:  
2024-04-08 04:54:29.688536: Epoch 106 
2024-04-08 04:54:29.688620: Current learning rate: 0.00904 
2024-04-08 04:54:39.189237: train_loss -0.9285 
2024-04-08 04:54:39.189541: val_loss -0.762 
2024-04-08 04:54:39.189702: Pseudo dice [0.8142] 
2024-04-08 04:54:39.189874: Epoch time: 9.5 s 
2024-04-08 04:54:40.171416:  
2024-04-08 04:54:40.171514: Epoch 107 
2024-04-08 04:54:40.171626: Current learning rate: 0.00903 
2024-04-08 04:54:49.451988: train_loss -0.9229 
2024-04-08 04:54:49.452121: val_loss -0.7556 
2024-04-08 04:54:49.452180: Pseudo dice [0.803] 
2024-04-08 04:54:49.452235: Epoch time: 9.28 s 
2024-04-08 04:54:50.455537:  
2024-04-08 04:54:50.455727: Epoch 108 
2024-04-08 04:54:50.455823: Current learning rate: 0.00902 
2024-04-08 04:54:59.551751: train_loss -0.9251 
2024-04-08 04:54:59.551947: val_loss -0.7639 
2024-04-08 04:54:59.552058: Pseudo dice [0.8164] 
2024-04-08 04:54:59.552164: Epoch time: 9.1 s 
2024-04-08 04:55:00.563985:  
2024-04-08 04:55:00.564181: Epoch 109 
2024-04-08 04:55:00.564263: Current learning rate: 0.00901 
2024-04-08 04:55:09.515853: train_loss -0.9287 
2024-04-08 04:55:09.516056: val_loss -0.7688 
2024-04-08 04:55:09.516159: Pseudo dice [0.8148] 
2024-04-08 04:55:09.516268: Epoch time: 8.95 s 
2024-04-08 04:55:10.534833:  
2024-04-08 04:55:10.534925: Epoch 110 
2024-04-08 04:55:10.535036: Current learning rate: 0.009 
2024-04-08 04:55:19.786725: train_loss -0.9271 
2024-04-08 04:55:19.787029: val_loss -0.765 
2024-04-08 04:55:19.787254: Pseudo dice [0.8163] 
2024-04-08 04:55:19.787489: Epoch time: 9.25 s 
2024-04-08 04:55:20.801298:  
2024-04-08 04:55:20.801404: Epoch 111 
2024-04-08 04:55:20.801484: Current learning rate: 0.009 
2024-04-08 04:55:30.139919: train_loss -0.9287 
2024-04-08 04:55:30.140095: val_loss -0.7778 
2024-04-08 04:55:30.140178: Pseudo dice [0.817] 
2024-04-08 04:55:30.140259: Epoch time: 9.34 s 
2024-04-08 04:55:31.104757:  
2024-04-08 04:55:31.104863: Epoch 112 
2024-04-08 04:55:31.104944: Current learning rate: 0.00899 
2024-04-08 04:55:40.425065: train_loss -0.9277 
2024-04-08 04:55:40.425227: val_loss -0.7849 
2024-04-08 04:55:40.425289: Pseudo dice [0.8244] 
2024-04-08 04:55:40.425349: Epoch time: 9.32 s 
2024-04-08 04:55:41.415215:  
2024-04-08 04:55:41.415329: Epoch 113 
2024-04-08 04:55:41.415407: Current learning rate: 0.00898 
2024-04-08 04:55:49.744900: train_loss -0.9289 
2024-04-08 04:55:49.745121: val_loss -0.777 
2024-04-08 04:55:49.745258: Pseudo dice [0.8179] 
2024-04-08 04:55:49.745347: Epoch time: 8.33 s 
2024-04-08 04:55:50.720659:  
2024-04-08 04:55:50.720846: Epoch 114 
2024-04-08 04:55:50.720925: Current learning rate: 0.00897 
2024-04-08 04:55:59.691526: train_loss -0.9275 
2024-04-08 04:55:59.691714: val_loss -0.766 
2024-04-08 04:55:59.691944: Pseudo dice [0.8091] 
2024-04-08 04:55:59.692054: Epoch time: 8.97 s 
2024-04-08 04:56:00.661297:  
2024-04-08 04:56:00.661398: Epoch 115 
2024-04-08 04:56:00.661477: Current learning rate: 0.00896 
2024-04-08 04:56:09.730325: train_loss -0.9289 
2024-04-08 04:56:09.730465: val_loss -0.7665 
2024-04-08 04:56:09.730527: Pseudo dice [0.8154] 
2024-04-08 04:56:09.730582: Epoch time: 9.07 s 
2024-04-08 04:56:10.944281:  
2024-04-08 04:56:10.944392: Epoch 116 
2024-04-08 04:56:10.944498: Current learning rate: 0.00895 
2024-04-08 04:56:20.450329: train_loss -0.9315 
2024-04-08 04:56:20.450512: val_loss -0.759 
2024-04-08 04:56:20.450592: Pseudo dice [0.8061] 
2024-04-08 04:56:20.450669: Epoch time: 9.51 s 
2024-04-08 04:56:21.457669:  
2024-04-08 04:56:21.457794: Epoch 117 
2024-04-08 04:56:21.457872: Current learning rate: 0.00894 
2024-04-08 04:56:30.812868: train_loss -0.9279 
2024-04-08 04:56:30.813045: val_loss -0.7599 
2024-04-08 04:56:30.813105: Pseudo dice [0.8081] 
2024-04-08 04:56:30.813165: Epoch time: 9.36 s 
2024-04-08 04:56:31.812563:  
2024-04-08 04:56:31.812883: Epoch 118 
2024-04-08 04:56:31.812966: Current learning rate: 0.00893 
2024-04-08 04:56:40.955509: train_loss -0.9217 
2024-04-08 04:56:40.955676: val_loss -0.766 
2024-04-08 04:56:40.955896: Pseudo dice [0.8141] 
2024-04-08 04:56:40.955990: Epoch time: 9.14 s 
2024-04-08 04:56:41.978667:  
2024-04-08 04:56:41.978797: Epoch 119 
2024-04-08 04:56:41.978965: Current learning rate: 0.00892 
2024-04-08 04:56:51.206026: train_loss -0.9202 
2024-04-08 04:56:51.206353: val_loss -0.7739 
2024-04-08 04:56:51.206486: Pseudo dice [0.8196] 
2024-04-08 04:56:51.206587: Epoch time: 9.23 s 
2024-04-08 04:56:52.191330:  
2024-04-08 04:56:52.191422: Epoch 120 
2024-04-08 04:56:52.191533: Current learning rate: 0.00891 
2024-04-08 04:57:01.589431: train_loss -0.9233 
2024-04-08 04:57:01.589574: val_loss -0.784 
2024-04-08 04:57:01.589636: Pseudo dice [0.8297] 
2024-04-08 04:57:01.589694: Epoch time: 9.4 s 
2024-04-08 04:57:02.743981:  
2024-04-08 04:57:02.744257: Epoch 121 
2024-04-08 04:57:02.744425: Current learning rate: 0.0089 
2024-04-08 04:57:11.745042: train_loss -0.9264 
2024-04-08 04:57:11.745215: val_loss -0.7761 
2024-04-08 04:57:11.745300: Pseudo dice [0.8174] 
2024-04-08 04:57:11.745375: Epoch time: 9.0 s 
2024-04-08 04:57:12.795199:  
2024-04-08 04:57:12.795421: Epoch 122 
2024-04-08 04:57:12.795504: Current learning rate: 0.00889 
2024-04-08 04:57:22.340265: train_loss -0.9289 
2024-04-08 04:57:22.340652: val_loss -0.7761 
2024-04-08 04:57:22.340808: Pseudo dice [0.8185] 
2024-04-08 04:57:22.341190: Epoch time: 9.55 s 
2024-04-08 04:57:23.422302:  
2024-04-08 04:57:23.422416: Epoch 123 
2024-04-08 04:57:23.422513: Current learning rate: 0.00889 
2024-04-08 04:57:32.539538: train_loss -0.929 
2024-04-08 04:57:32.539733: val_loss -0.7694 
2024-04-08 04:57:32.539810: Pseudo dice [0.8153] 
2024-04-08 04:57:32.539922: Epoch time: 9.12 s 
2024-04-08 04:57:33.542217:  
2024-04-08 04:57:33.542325: Epoch 124 
2024-04-08 04:57:33.542430: Current learning rate: 0.00888 
