
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 32, 'patch_size': [128, 112], 'median_image_size_in_voxels': [128.0, 108.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 5, 'features_per_stage': [32, 64, 128, 256, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset500_ATLAS', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [999.0, 1.0, 1.0], 'original_median_shape_after_transp': [1, 128, 108], 'image_reader_writer': 'NaturalImage2DIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 255.0, 'mean': 106.32513488594138, 'median': 104.0, 'min': 5.0, 'percentile_00_5': 13.0, 'percentile_99_5': 225.0, 'std': 45.25044338801177}}} 
 
2024-04-08 04:57:47.067125: unpacking dataset... 
2024-04-08 04:57:49.804040: unpacking done... 
2024-04-08 04:57:49.804401: do_dummy_2d_data_aug: False 
2024-04-08 04:57:49.808324: Using splits from existing split file: /home/malek/autoDDPM/nnunet_data/nnunet_preprocessed/Dataset500_ATLAS/splits_final.json 
2024-04-08 04:57:49.809156: The split file contains 5 splits. 
2024-04-08 04:57:49.809230: Desired fold for training: 4 
2024-04-08 04:57:49.809276: This split has 524 training and 131 validation cases. 
2024-04-08 04:57:49.818893: Unable to plot network architecture: 
2024-04-08 04:57:49.819029: No module named 'hiddenlayer' 
2024-04-08 04:57:49.827377:  
2024-04-08 04:57:49.827536: Epoch 0 
2024-04-08 04:57:49.827720: Current learning rate: 0.01 
2024-04-08 04:58:02.688126: train_loss 0.0648 
2024-04-08 04:58:02.688294: val_loss -0.031 
2024-04-08 04:58:02.688357: Pseudo dice [0.0] 
2024-04-08 04:58:02.688421: Epoch time: 12.86 s 
2024-04-08 04:58:02.688514: Yayy! New best EMA pseudo Dice: 0.0 
2024-04-08 04:58:03.637974:  
2024-04-08 04:58:03.638146: Epoch 1 
2024-04-08 04:58:03.638421: Current learning rate: 0.00999 
2024-04-08 04:58:12.861362: train_loss -0.3742 
2024-04-08 04:58:12.861511: val_loss -0.6699 
2024-04-08 04:58:12.861574: Pseudo dice [0.7334] 
2024-04-08 04:58:12.861644: Epoch time: 9.22 s 
2024-04-08 04:58:12.861692: Yayy! New best EMA pseudo Dice: 0.0733 
2024-04-08 04:58:13.958070:  
2024-04-08 04:58:13.958181: Epoch 2 
2024-04-08 04:58:13.958281: Current learning rate: 0.00998 
2024-04-08 04:58:23.051704: train_loss -0.6332 
2024-04-08 04:58:23.051841: val_loss -0.7024 
2024-04-08 04:58:23.051896: Pseudo dice [0.7605] 
2024-04-08 04:58:23.051949: Epoch time: 9.09 s 
2024-04-08 04:58:23.051993: Yayy! New best EMA pseudo Dice: 0.1421 
2024-04-08 04:58:24.379631:  
2024-04-08 04:58:24.379759: Epoch 3 
2024-04-08 04:58:24.379866: Current learning rate: 0.00997 
2024-04-08 04:58:33.587457: train_loss -0.6879 
2024-04-08 04:58:33.587632: val_loss -0.7422 
2024-04-08 04:58:33.588032: Pseudo dice [0.7911] 
2024-04-08 04:58:33.588205: Epoch time: 9.21 s 
2024-04-08 04:58:33.588467: Yayy! New best EMA pseudo Dice: 0.207 
2024-04-08 04:58:34.814274:  
2024-04-08 04:58:34.814392: Epoch 4 
2024-04-08 04:58:34.814487: Current learning rate: 0.00996 
2024-04-08 04:58:44.010894: train_loss -0.7256 
2024-04-08 04:58:44.011044: val_loss -0.7346 
2024-04-08 04:58:44.011102: Pseudo dice [0.7875] 
2024-04-08 04:58:44.011156: Epoch time: 9.2 s 
2024-04-08 04:58:44.011200: Yayy! New best EMA pseudo Dice: 0.265 
2024-04-08 04:58:45.174045:  
2024-04-08 04:58:45.174150: Epoch 5 
2024-04-08 04:58:45.174270: Current learning rate: 0.00995 
2024-04-08 04:58:54.618995: train_loss -0.734 
2024-04-08 04:58:54.619207: val_loss -0.7393 
2024-04-08 04:58:54.619428: Pseudo dice [0.7917] 
2024-04-08 04:58:54.619538: Epoch time: 9.45 s 
2024-04-08 04:58:54.619658: Yayy! New best EMA pseudo Dice: 0.3177 
2024-04-08 04:58:55.692601:  
2024-04-08 04:58:55.692704: Epoch 6 
2024-04-08 04:58:55.692788: Current learning rate: 0.00995 
2024-04-08 04:59:04.906662: train_loss -0.7535 
2024-04-08 04:59:04.906851: val_loss -0.7452 
2024-04-08 04:59:04.906914: Pseudo dice [0.7956] 
2024-04-08 04:59:04.906980: Epoch time: 9.21 s 
2024-04-08 04:59:04.907026: Yayy! New best EMA pseudo Dice: 0.3655 
2024-04-08 04:59:05.985370:  
2024-04-08 04:59:05.985471: Epoch 7 
2024-04-08 04:59:05.985552: Current learning rate: 0.00994 
2024-04-08 04:59:14.865425: train_loss -0.7611 
2024-04-08 04:59:14.865581: val_loss -0.7566 
2024-04-08 04:59:14.865643: Pseudo dice [0.8018] 
2024-04-08 04:59:14.865714: Epoch time: 8.88 s 
2024-04-08 04:59:14.865772: Yayy! New best EMA pseudo Dice: 0.4091 
2024-04-08 04:59:16.019558:  
2024-04-08 04:59:16.019691: Epoch 8 
2024-04-08 04:59:16.019791: Current learning rate: 0.00993 
2024-04-08 04:59:25.301215: train_loss -0.7753 
2024-04-08 04:59:25.301835: val_loss -0.7612 
2024-04-08 04:59:25.301975: Pseudo dice [0.8033] 
2024-04-08 04:59:25.302078: Epoch time: 9.28 s 
2024-04-08 04:59:25.302186: Yayy! New best EMA pseudo Dice: 0.4485 
2024-04-08 04:59:26.568569:  
2024-04-08 04:59:26.568801: Epoch 9 
2024-04-08 04:59:26.568881: Current learning rate: 0.00992 
2024-04-08 04:59:35.617097: train_loss -0.7843 
2024-04-08 04:59:35.617350: val_loss -0.7383 
2024-04-08 04:59:35.617475: Pseudo dice [0.7918] 
2024-04-08 04:59:35.617661: Epoch time: 9.05 s 
2024-04-08 04:59:35.617871: Yayy! New best EMA pseudo Dice: 0.4829 
2024-04-08 04:59:36.702133:  
2024-04-08 04:59:36.702260: Epoch 10 
2024-04-08 04:59:36.702354: Current learning rate: 0.00991 
2024-04-08 04:59:46.146553: train_loss -0.7751 
2024-04-08 04:59:46.146694: val_loss -0.7543 
2024-04-08 04:59:46.146750: Pseudo dice [0.8039] 
2024-04-08 04:59:46.146809: Epoch time: 9.45 s 
2024-04-08 04:59:46.146853: Yayy! New best EMA pseudo Dice: 0.515 
2024-04-08 04:59:47.322106:  
2024-04-08 04:59:47.322223: Epoch 11 
2024-04-08 04:59:47.322302: Current learning rate: 0.0099 
2024-04-08 04:59:56.827509: train_loss -0.7988 
2024-04-08 04:59:56.827645: val_loss -0.7675 
2024-04-08 04:59:56.827722: Pseudo dice [0.8142] 
2024-04-08 04:59:56.827782: Epoch time: 9.51 s 
2024-04-08 04:59:56.827830: Yayy! New best EMA pseudo Dice: 0.5449 
2024-04-08 04:59:57.918795:  
2024-04-08 04:59:57.918909: Epoch 12 
2024-04-08 04:59:57.919005: Current learning rate: 0.00989 
2024-04-08 05:00:07.203465: train_loss -0.8111 
2024-04-08 05:00:07.203624: val_loss -0.7736 
2024-04-08 05:00:07.203698: Pseudo dice [0.8203] 
2024-04-08 05:00:07.203771: Epoch time: 9.29 s 
2024-04-08 05:00:07.203842: Yayy! New best EMA pseudo Dice: 0.5724 
2024-04-08 05:00:08.310143:  
2024-04-08 05:00:08.310344: Epoch 13 
2024-04-08 05:00:08.310425: Current learning rate: 0.00988 
2024-04-08 05:00:17.419221: train_loss -0.8084 
2024-04-08 05:00:17.419355: val_loss -0.7666 
2024-04-08 05:00:17.419411: Pseudo dice [0.8167] 
2024-04-08 05:00:17.419467: Epoch time: 9.11 s 
2024-04-08 05:00:17.419511: Yayy! New best EMA pseudo Dice: 0.5969 
2024-04-08 05:00:18.693017:  
2024-04-08 05:00:18.693285: Epoch 14 
2024-04-08 05:00:18.693456: Current learning rate: 0.00987 
2024-04-08 05:00:27.352592: train_loss -0.8216 
2024-04-08 05:00:27.352918: val_loss -0.7735 
2024-04-08 05:00:27.353108: Pseudo dice [0.8143] 
2024-04-08 05:00:27.353237: Epoch time: 8.66 s 
2024-04-08 05:00:27.353294: Yayy! New best EMA pseudo Dice: 0.6186 
2024-04-08 05:00:28.516612:  
2024-04-08 05:00:28.516714: Epoch 15 
2024-04-08 05:00:28.516794: Current learning rate: 0.00986 
2024-04-08 05:00:37.461177: train_loss -0.8142 
2024-04-08 05:00:37.461326: val_loss -0.7761 
2024-04-08 05:00:37.461389: Pseudo dice [0.821] 
2024-04-08 05:00:37.461452: Epoch time: 8.95 s 
2024-04-08 05:00:37.461502: Yayy! New best EMA pseudo Dice: 0.6388 
2024-04-08 05:00:38.611015:  
2024-04-08 05:00:38.611110: Epoch 16 
2024-04-08 05:00:38.611204: Current learning rate: 0.00986 
2024-04-08 05:00:47.616620: train_loss -0.8255 
2024-04-08 05:00:47.616815: val_loss -0.7694 
2024-04-08 05:00:47.616880: Pseudo dice [0.813] 
2024-04-08 05:00:47.616939: Epoch time: 9.01 s 
2024-04-08 05:00:47.617077: Yayy! New best EMA pseudo Dice: 0.6562 
2024-04-08 05:00:48.790384:  
2024-04-08 05:00:48.790501: Epoch 17 
2024-04-08 05:00:48.790604: Current learning rate: 0.00985 
2024-04-08 05:00:58.048274: train_loss -0.8286 
2024-04-08 05:00:58.048521: val_loss -0.7799 
2024-04-08 05:00:58.048650: Pseudo dice [0.8237] 
2024-04-08 05:00:58.048854: Epoch time: 9.26 s 
2024-04-08 05:00:58.048936: Yayy! New best EMA pseudo Dice: 0.673 
2024-04-08 05:00:59.179244:  
2024-04-08 05:00:59.179580: Epoch 18 
2024-04-08 05:00:59.179663: Current learning rate: 0.00984 
2024-04-08 05:01:07.931364: train_loss -0.8312 
2024-04-08 05:01:07.931576: val_loss -0.7845 
2024-04-08 05:01:07.931705: Pseudo dice [0.8272] 
2024-04-08 05:01:07.931782: Epoch time: 8.75 s 
2024-04-08 05:01:07.931831: Yayy! New best EMA pseudo Dice: 0.6884 
2024-04-08 05:01:09.216427:  
2024-04-08 05:01:09.216759: Epoch 19 
2024-04-08 05:01:09.216845: Current learning rate: 0.00983 
2024-04-08 05:01:18.533394: train_loss -0.8213 
2024-04-08 05:01:18.533539: val_loss -0.7693 
2024-04-08 05:01:18.533626: Pseudo dice [0.8181] 
2024-04-08 05:01:18.533685: Epoch time: 9.32 s 
2024-04-08 05:01:18.533741: Yayy! New best EMA pseudo Dice: 0.7014 
2024-04-08 05:01:19.631395:  
2024-04-08 05:01:19.631517: Epoch 20 
2024-04-08 05:01:19.631596: Current learning rate: 0.00982 
2024-04-08 05:01:28.638192: train_loss -0.8283 
2024-04-08 05:01:28.638473: val_loss -0.7802 
2024-04-08 05:01:28.638626: Pseudo dice [0.8234] 
2024-04-08 05:01:28.638792: Epoch time: 9.01 s 
2024-04-08 05:01:28.638922: Yayy! New best EMA pseudo Dice: 0.7136 
2024-04-08 05:01:29.801864:  
2024-04-08 05:01:29.802049: Epoch 21 
2024-04-08 05:01:29.802147: Current learning rate: 0.00981 
2024-04-08 05:01:39.312844: train_loss -0.8361 
2024-04-08 05:01:39.312991: val_loss -0.7814 
2024-04-08 05:01:39.313331: Pseudo dice [0.8272] 
2024-04-08 05:01:39.313411: Epoch time: 9.51 s 
2024-04-08 05:01:39.313496: Yayy! New best EMA pseudo Dice: 0.7249 
2024-04-08 05:01:40.369650:  
2024-04-08 05:01:40.369749: Epoch 22 
2024-04-08 05:01:40.369827: Current learning rate: 0.0098 
2024-04-08 05:01:49.010525: train_loss -0.8397 
2024-04-08 05:01:49.010664: val_loss -0.7686 
2024-04-08 05:01:49.010740: Pseudo dice [0.8085] 
2024-04-08 05:01:49.010798: Epoch time: 8.64 s 
2024-04-08 05:01:49.010846: Yayy! New best EMA pseudo Dice: 0.7333 
2024-04-08 05:01:50.073789:  
2024-04-08 05:01:50.074085: Epoch 23 
2024-04-08 05:01:50.074252: Current learning rate: 0.00979 
2024-04-08 05:01:59.290436: train_loss -0.8437 
2024-04-08 05:01:59.291092: val_loss -0.7781 
2024-04-08 05:01:59.291228: Pseudo dice [0.8186] 
2024-04-08 05:01:59.291364: Epoch time: 9.22 s 
2024-04-08 05:01:59.291432: Yayy! New best EMA pseudo Dice: 0.7418 
2024-04-08 05:02:00.356095:  
2024-04-08 05:02:00.356298: Epoch 24 
2024-04-08 05:02:00.356537: Current learning rate: 0.00978 
2024-04-08 05:02:09.466620: train_loss -0.8385 
2024-04-08 05:02:09.466873: val_loss -0.7399 
2024-04-08 05:02:09.466938: Pseudo dice [0.7933] 
2024-04-08 05:02:09.467067: Epoch time: 9.11 s 
2024-04-08 05:02:09.467177: Yayy! New best EMA pseudo Dice: 0.747 
2024-04-08 05:02:10.521118:  
2024-04-08 05:02:10.521221: Epoch 25 
2024-04-08 05:02:10.521298: Current learning rate: 0.00977 
2024-04-08 05:02:19.983416: train_loss -0.8434 
2024-04-08 05:02:19.983713: val_loss -0.7803 
2024-04-08 05:02:19.983870: Pseudo dice [0.8254] 
2024-04-08 05:02:19.984036: Epoch time: 9.46 s 
2024-04-08 05:02:19.984167: Yayy! New best EMA pseudo Dice: 0.7548 
2024-04-08 05:02:21.074642:  
2024-04-08 05:02:21.074926: Epoch 26 
2024-04-08 05:02:21.075109: Current learning rate: 0.00977 
2024-04-08 05:02:30.428639: train_loss -0.8454 
2024-04-08 05:02:30.428784: val_loss -0.7848 
2024-04-08 05:02:30.428846: Pseudo dice [0.8246] 
2024-04-08 05:02:30.428905: Epoch time: 9.35 s 
2024-04-08 05:02:30.428954: Yayy! New best EMA pseudo Dice: 0.7618 
2024-04-08 05:02:31.496968:  
2024-04-08 05:02:31.497151: Epoch 27 
2024-04-08 05:02:31.497234: Current learning rate: 0.00976 
2024-04-08 05:02:40.864928: train_loss -0.8587 
2024-04-08 05:02:40.865079: val_loss -0.7809 
2024-04-08 05:02:40.865141: Pseudo dice [0.8247] 
2024-04-08 05:02:40.865200: Epoch time: 9.37 s 
2024-04-08 05:02:40.865250: Yayy! New best EMA pseudo Dice: 0.7681 
2024-04-08 05:02:41.946975:  
2024-04-08 05:02:41.947072: Epoch 28 
2024-04-08 05:02:41.947166: Current learning rate: 0.00975 
2024-04-08 05:02:51.134008: train_loss -0.8565 
2024-04-08 05:02:51.134152: val_loss -0.785 
2024-04-08 05:02:51.134228: Pseudo dice [0.8272] 
2024-04-08 05:02:51.134296: Epoch time: 9.19 s 
2024-04-08 05:02:51.134346: Yayy! New best EMA pseudo Dice: 0.774 
2024-04-08 05:02:52.340295:  
2024-04-08 05:02:52.340404: Epoch 29 
2024-04-08 05:02:52.340495: Current learning rate: 0.00974 
2024-04-08 05:03:01.273831: train_loss -0.8605 
2024-04-08 05:03:01.274027: val_loss -0.7744 
2024-04-08 05:03:01.274108: Pseudo dice [0.8174] 
2024-04-08 05:03:01.274257: Epoch time: 8.93 s 
2024-04-08 05:03:01.274498: Yayy! New best EMA pseudo Dice: 0.7783 
2024-04-08 05:03:02.411119:  
2024-04-08 05:03:02.411219: Epoch 30 
2024-04-08 05:03:02.411330: Current learning rate: 0.00973 
2024-04-08 05:03:11.757804: train_loss -0.8642 
2024-04-08 05:03:11.758019: val_loss -0.7951 
2024-04-08 05:03:11.758126: Pseudo dice [0.8326] 
2024-04-08 05:03:11.758228: Epoch time: 9.35 s 
2024-04-08 05:03:11.758315: Yayy! New best EMA pseudo Dice: 0.7838 
2024-04-08 05:03:12.862960:  
2024-04-08 05:03:12.863081: Epoch 31 
2024-04-08 05:03:12.863162: Current learning rate: 0.00972 
2024-04-08 05:03:21.618638: train_loss -0.867 
2024-04-08 05:03:21.618774: val_loss -0.7858 
2024-04-08 05:03:21.618834: Pseudo dice [0.83] 
2024-04-08 05:03:21.618906: Epoch time: 8.76 s 
2024-04-08 05:03:21.618961: Yayy! New best EMA pseudo Dice: 0.7884 
2024-04-08 05:03:22.742329:  
2024-04-08 05:03:22.742755: Epoch 32 
2024-04-08 05:03:22.742839: Current learning rate: 0.00971 
2024-04-08 05:03:31.382276: train_loss -0.871 
2024-04-08 05:03:31.382555: val_loss -0.7858 
2024-04-08 05:03:31.382711: Pseudo dice [0.8266] 
2024-04-08 05:03:31.382875: Epoch time: 8.64 s 
2024-04-08 05:03:31.383003: Yayy! New best EMA pseudo Dice: 0.7922 
2024-04-08 05:03:32.572104:  
2024-04-08 05:03:32.572275: Epoch 33 
2024-04-08 05:03:32.572358: Current learning rate: 0.0097 
2024-04-08 05:03:42.014596: train_loss -0.8715 
2024-04-08 05:03:42.014771: val_loss -0.7749 
2024-04-08 05:03:42.014875: Pseudo dice [0.8228] 
2024-04-08 05:03:42.014953: Epoch time: 9.44 s 
2024-04-08 05:03:42.015022: Yayy! New best EMA pseudo Dice: 0.7953 
2024-04-08 05:03:43.172739:  
2024-04-08 05:03:43.172845: Epoch 34 
2024-04-08 05:03:43.172923: Current learning rate: 0.00969 
2024-04-08 05:03:51.879557: train_loss -0.8743 
2024-04-08 05:03:51.879904: val_loss -0.7573 
2024-04-08 05:03:51.880044: Pseudo dice [0.8047] 
2024-04-08 05:03:51.880474: Epoch time: 8.71 s 
2024-04-08 05:03:51.880831: Yayy! New best EMA pseudo Dice: 0.7962 
2024-04-08 05:03:53.041865:  
2024-04-08 05:03:53.041974: Epoch 35 
2024-04-08 05:03:53.042051: Current learning rate: 0.00968 
2024-04-08 05:04:02.585805: train_loss -0.877 
2024-04-08 05:04:02.586028: val_loss -0.7752 
2024-04-08 05:04:02.586257: Pseudo dice [0.8197] 
2024-04-08 05:04:02.586401: Epoch time: 9.54 s 
2024-04-08 05:04:02.586481: Yayy! New best EMA pseudo Dice: 0.7986 
2024-04-08 05:04:03.749388:  
2024-04-08 05:04:03.749491: Epoch 36 
2024-04-08 05:04:03.749571: Current learning rate: 0.00968 
2024-04-08 05:04:12.489662: train_loss -0.8831 
2024-04-08 05:04:12.489979: val_loss -0.7739 
2024-04-08 05:04:12.490156: Pseudo dice [0.8154] 
2024-04-08 05:04:12.490286: Epoch time: 8.74 s 
2024-04-08 05:04:12.490401: Yayy! New best EMA pseudo Dice: 0.8003 
2024-04-08 05:04:13.633922:  
2024-04-08 05:04:13.634022: Epoch 37 
2024-04-08 05:04:13.634101: Current learning rate: 0.00967 
2024-04-08 05:04:22.620177: train_loss -0.8801 
2024-04-08 05:04:22.620494: val_loss -0.7751 
2024-04-08 05:04:22.620683: Pseudo dice [0.8162] 
2024-04-08 05:04:22.620850: Epoch time: 8.99 s 
2024-04-08 05:04:22.620995: Yayy! New best EMA pseudo Dice: 0.8018 
2024-04-08 05:04:23.934662:  
2024-04-08 05:04:23.934800: Epoch 38 
2024-04-08 05:04:23.934916: Current learning rate: 0.00966 
2024-04-08 05:04:33.019536: train_loss -0.8787 
2024-04-08 05:04:33.019766: val_loss -0.7861 
2024-04-08 05:04:33.019953: Pseudo dice [0.8321] 
2024-04-08 05:04:33.020277: Epoch time: 9.09 s 
2024-04-08 05:04:33.020474: Yayy! New best EMA pseudo Dice: 0.8049 
2024-04-08 05:04:34.128619:  
2024-04-08 05:04:34.128723: Epoch 39 
2024-04-08 05:04:34.128801: Current learning rate: 0.00965 
2024-04-08 05:04:43.248977: train_loss -0.8838 
2024-04-08 05:04:43.249187: val_loss -0.7831 
2024-04-08 05:04:43.249247: Pseudo dice [0.8281] 
2024-04-08 05:04:43.249367: Epoch time: 9.12 s 
2024-04-08 05:04:43.249518: Yayy! New best EMA pseudo Dice: 0.8072 
2024-04-08 05:04:44.395254:  
2024-04-08 05:04:44.395373: Epoch 40 
2024-04-08 05:04:44.395467: Current learning rate: 0.00964 
2024-04-08 05:04:53.607780: train_loss -0.882 
2024-04-08 05:04:53.607965: val_loss -0.7763 
2024-04-08 05:04:53.608031: Pseudo dice [0.8234] 
2024-04-08 05:04:53.608094: Epoch time: 9.21 s 
2024-04-08 05:04:53.608144: Yayy! New best EMA pseudo Dice: 0.8088 
2024-04-08 05:04:54.829203:  
2024-04-08 05:04:54.829301: Epoch 41 
2024-04-08 05:04:54.829381: Current learning rate: 0.00963 
2024-04-08 05:05:03.923414: train_loss -0.8845 
2024-04-08 05:05:03.923553: val_loss -0.7699 
2024-04-08 05:05:03.923610: Pseudo dice [0.8167] 
2024-04-08 05:05:03.923800: Epoch time: 9.09 s 
2024-04-08 05:05:03.923951: Yayy! New best EMA pseudo Dice: 0.8096 
2024-04-08 05:05:04.973560:  
2024-04-08 05:05:04.973658: Epoch 42 
2024-04-08 05:05:04.973737: Current learning rate: 0.00962 
2024-04-08 05:05:14.074730: train_loss -0.8863 
2024-04-08 05:05:14.074868: val_loss -0.791 
2024-04-08 05:05:14.074926: Pseudo dice [0.8334] 
2024-04-08 05:05:14.074979: Epoch time: 9.1 s 
2024-04-08 05:05:14.075024: Yayy! New best EMA pseudo Dice: 0.812 
2024-04-08 05:05:15.111865:  
2024-04-08 05:05:15.111964: Epoch 43 
2024-04-08 05:05:15.112045: Current learning rate: 0.00961 
2024-04-08 05:05:24.367797: train_loss -0.8897 
2024-04-08 05:05:24.368101: val_loss -0.7761 
2024-04-08 05:05:24.368362: Pseudo dice [0.8204] 
2024-04-08 05:05:24.368623: Epoch time: 9.26 s 
2024-04-08 05:05:24.369307: Yayy! New best EMA pseudo Dice: 0.8128 
2024-04-08 05:05:25.446230:  
2024-04-08 05:05:25.446341: Epoch 44 
2024-04-08 05:05:25.446418: Current learning rate: 0.0096 
2024-04-08 05:05:34.560773: train_loss -0.8914 
2024-04-08 05:05:34.561133: val_loss -0.765 
2024-04-08 05:05:34.561322: Pseudo dice [0.816] 
2024-04-08 05:05:34.561433: Epoch time: 9.12 s 
2024-04-08 05:05:34.561502: Yayy! New best EMA pseudo Dice: 0.8131 
2024-04-08 05:05:35.676710:  
2024-04-08 05:05:35.676812: Epoch 45 
2024-04-08 05:05:35.676890: Current learning rate: 0.00959 
2024-04-08 05:05:44.854320: train_loss -0.887 
2024-04-08 05:05:44.854521: val_loss -0.7968 
2024-04-08 05:05:44.854694: Pseudo dice [0.8408] 
2024-04-08 05:05:44.854757: Epoch time: 9.18 s 
2024-04-08 05:05:44.854806: Yayy! New best EMA pseudo Dice: 0.8159 
2024-04-08 05:05:45.910349:  
2024-04-08 05:05:45.910456: Epoch 46 
2024-04-08 05:05:45.910533: Current learning rate: 0.00959 
2024-04-08 05:05:54.670865: train_loss -0.8901 
2024-04-08 05:05:54.671069: val_loss -0.7944 
2024-04-08 05:05:54.671154: Pseudo dice [0.8387] 
2024-04-08 05:05:54.671214: Epoch time: 8.76 s 
2024-04-08 05:05:54.671288: Yayy! New best EMA pseudo Dice: 0.8182 
2024-04-08 05:05:55.744601:  
2024-04-08 05:05:55.744700: Epoch 47 
2024-04-08 05:05:55.744794: Current learning rate: 0.00958 
2024-04-08 05:06:05.060928: train_loss -0.8944 
2024-04-08 05:06:05.061090: val_loss -0.767 
2024-04-08 05:06:05.061161: Pseudo dice [0.8096] 
2024-04-08 05:06:05.061230: Epoch time: 9.32 s 
2024-04-08 05:06:06.010351:  
2024-04-08 05:06:06.010475: Epoch 48 
2024-04-08 05:06:06.010556: Current learning rate: 0.00957 
2024-04-08 05:06:14.989867: train_loss -0.8887 
2024-04-08 05:06:14.990013: val_loss -0.7794 
2024-04-08 05:06:14.990088: Pseudo dice [0.824] 
2024-04-08 05:06:14.990147: Epoch time: 8.98 s 
2024-04-08 05:06:16.138252:  
2024-04-08 05:06:16.138370: Epoch 49 
2024-04-08 05:06:16.138456: Current learning rate: 0.00956 
2024-04-08 05:06:25.235029: train_loss -0.8941 
2024-04-08 05:06:25.235193: val_loss -0.7922 
2024-04-08 05:06:25.235254: Pseudo dice [0.8345] 
2024-04-08 05:06:25.235313: Epoch time: 9.1 s 
2024-04-08 05:06:25.306391: Yayy! New best EMA pseudo Dice: 0.8196 
2024-04-08 05:06:26.368801:  
2024-04-08 05:06:26.368969: Epoch 50 
2024-04-08 05:06:26.369052: Current learning rate: 0.00955 
2024-04-08 05:06:35.472270: train_loss -0.8933 
2024-04-08 05:06:35.472412: val_loss -0.7936 
2024-04-08 05:06:35.472502: Pseudo dice [0.8387] 
2024-04-08 05:06:35.472565: Epoch time: 9.1 s 
2024-04-08 05:06:35.472621: Yayy! New best EMA pseudo Dice: 0.8215 
2024-04-08 05:06:36.580572:  
2024-04-08 05:06:36.580684: Epoch 51 
2024-04-08 05:06:36.580764: Current learning rate: 0.00954 
2024-04-08 05:06:45.973910: train_loss -0.8938 
2024-04-08 05:06:45.974196: val_loss -0.7861 
2024-04-08 05:06:45.974364: Pseudo dice [0.826] 
2024-04-08 05:06:45.974527: Epoch time: 9.39 s 
2024-04-08 05:06:45.974742: Yayy! New best EMA pseudo Dice: 0.822 
2024-04-08 05:06:47.067135:  
2024-04-08 05:06:47.067252: Epoch 52 
2024-04-08 05:06:47.067351: Current learning rate: 0.00953 
2024-04-08 05:06:56.494127: train_loss -0.8955 
2024-04-08 05:06:56.494309: val_loss -0.7819 
2024-04-08 05:06:56.494394: Pseudo dice [0.8272] 
2024-04-08 05:06:56.494473: Epoch time: 9.43 s 
2024-04-08 05:06:56.494539: Yayy! New best EMA pseudo Dice: 0.8225 
2024-04-08 05:06:57.610441:  
2024-04-08 05:06:57.610590: Epoch 53 
2024-04-08 05:06:57.610702: Current learning rate: 0.00952 
2024-04-08 05:07:06.667493: train_loss -0.8955 
2024-04-08 05:07:06.667629: val_loss -0.7964 
2024-04-08 05:07:06.667693: Pseudo dice [0.8372] 
2024-04-08 05:07:06.667748: Epoch time: 9.06 s 
2024-04-08 05:07:06.667794: Yayy! New best EMA pseudo Dice: 0.824 
2024-04-08 05:07:07.893341:  
2024-04-08 05:07:07.893456: Epoch 54 
2024-04-08 05:07:07.893536: Current learning rate: 0.00951 
2024-04-08 05:07:17.229478: train_loss -0.9017 
2024-04-08 05:07:17.229627: val_loss -0.7799 
2024-04-08 05:07:17.229700: Pseudo dice [0.8263] 
2024-04-08 05:07:17.229755: Epoch time: 9.34 s 
2024-04-08 05:07:17.229800: Yayy! New best EMA pseudo Dice: 0.8242 
2024-04-08 05:07:18.300146:  
2024-04-08 05:07:18.300255: Epoch 55 
2024-04-08 05:07:18.300333: Current learning rate: 0.0095 
2024-04-08 05:07:27.798035: train_loss -0.9043 
2024-04-08 05:07:27.798345: val_loss -0.7757 
2024-04-08 05:07:27.798504: Pseudo dice [0.8218] 
2024-04-08 05:07:27.798903: Epoch time: 9.5 s 
2024-04-08 05:07:28.766608:  
2024-04-08 05:07:28.766716: Epoch 56 
2024-04-08 05:07:28.766795: Current learning rate: 0.00949 
2024-04-08 05:07:37.928408: train_loss -0.9014 
2024-04-08 05:07:37.928628: val_loss -0.7872 
2024-04-08 05:07:37.928924: Pseudo dice [0.8301] 
2024-04-08 05:07:37.929062: Epoch time: 9.16 s 
2024-04-08 05:07:37.929191: Yayy! New best EMA pseudo Dice: 0.8246 
2024-04-08 05:07:39.026350:  
2024-04-08 05:07:39.026590: Epoch 57 
2024-04-08 05:07:39.026675: Current learning rate: 0.00949 
2024-04-08 05:07:48.340816: train_loss -0.9028 
2024-04-08 05:07:48.340965: val_loss -0.7799 
2024-04-08 05:07:48.341029: Pseudo dice [0.8227] 
2024-04-08 05:07:48.341089: Epoch time: 9.32 s 
2024-04-08 05:07:49.295632:  
2024-04-08 05:07:49.295743: Epoch 58 
2024-04-08 05:07:49.295819: Current learning rate: 0.00948 
2024-04-08 05:07:58.283469: train_loss -0.9026 
2024-04-08 05:07:58.283627: val_loss -0.7899 
2024-04-08 05:07:58.283724: Pseudo dice [0.8283] 
2024-04-08 05:07:58.283804: Epoch time: 8.99 s 
2024-04-08 05:07:58.283874: Yayy! New best EMA pseudo Dice: 0.8248 
2024-04-08 05:07:59.539995:  
2024-04-08 05:07:59.540099: Epoch 59 
2024-04-08 05:07:59.540194: Current learning rate: 0.00947 
2024-04-08 05:08:08.899261: train_loss -0.8994 
2024-04-08 05:08:08.899859: val_loss -0.7565 
2024-04-08 05:08:08.899975: Pseudo dice [0.802] 
2024-04-08 05:08:08.900032: Epoch time: 9.36 s 
2024-04-08 05:08:09.997598:  
2024-04-08 05:08:09.997705: Epoch 60 
2024-04-08 05:08:09.997783: Current learning rate: 0.00946 
2024-04-08 05:08:19.481257: train_loss -0.9016 
2024-04-08 05:08:19.481401: val_loss -0.767 
2024-04-08 05:08:19.481461: Pseudo dice [0.8149] 
2024-04-08 05:08:19.481519: Epoch time: 9.48 s 
2024-04-08 05:08:20.480165:  
2024-04-08 05:08:20.480440: Epoch 61 
2024-04-08 05:08:20.480608: Current learning rate: 0.00945 
2024-04-08 05:08:29.959704: train_loss -0.9021 
2024-04-08 05:08:29.959958: val_loss -0.7764 
2024-04-08 05:08:29.960037: Pseudo dice [0.8221] 
2024-04-08 05:08:29.960096: Epoch time: 9.48 s 
2024-04-08 05:08:30.976704:  
2024-04-08 05:08:30.976806: Epoch 62 
2024-04-08 05:08:30.976902: Current learning rate: 0.00944 
2024-04-08 05:08:40.308854: train_loss -0.8994 
2024-04-08 05:08:40.309001: val_loss -0.7704 
2024-04-08 05:08:40.309064: Pseudo dice [0.817] 
2024-04-08 05:08:40.309124: Epoch time: 9.33 s 
2024-04-08 05:08:41.347320:  
2024-04-08 05:08:41.347540: Epoch 63 
2024-04-08 05:08:41.347623: Current learning rate: 0.00943 
2024-04-08 05:08:50.697910: train_loss -0.9025 
2024-04-08 05:08:50.698189: val_loss -0.7667 
2024-04-08 05:08:50.698344: Pseudo dice [0.8132] 
2024-04-08 05:08:50.698510: Epoch time: 9.35 s 
2024-04-08 05:08:51.660783:  
2024-04-08 05:08:51.660879: Epoch 64 
2024-04-08 05:08:51.660960: Current learning rate: 0.00942 
2024-04-08 05:09:00.743677: train_loss -0.9036 
2024-04-08 05:09:00.743898: val_loss -0.7731 
2024-04-08 05:09:00.744028: Pseudo dice [0.8177] 
2024-04-08 05:09:00.744091: Epoch time: 9.08 s 
2024-04-08 05:09:01.937800:  
2024-04-08 05:09:01.937901: Epoch 65 
2024-04-08 05:09:01.937978: Current learning rate: 0.00941 
2024-04-08 05:09:10.811613: train_loss -0.9006 
2024-04-08 05:09:10.811938: val_loss -0.7687 
2024-04-08 05:09:10.812053: Pseudo dice [0.8136] 
2024-04-08 05:09:10.812177: Epoch time: 8.87 s 
2024-04-08 05:09:11.900789:  
2024-04-08 05:09:11.900893: Epoch 66 
2024-04-08 05:09:11.900972: Current learning rate: 0.0094 
2024-04-08 05:09:21.061259: train_loss -0.9026 
2024-04-08 05:09:21.061592: val_loss -0.7893 
2024-04-08 05:09:21.061773: Pseudo dice [0.8332] 
2024-04-08 05:09:21.061837: Epoch time: 9.16 s 
2024-04-08 05:09:22.065487:  
2024-04-08 05:09:22.065596: Epoch 67 
2024-04-08 05:09:22.065677: Current learning rate: 0.00939 
2024-04-08 05:09:31.481255: train_loss -0.9034 
2024-04-08 05:09:31.481403: val_loss -0.7706 
2024-04-08 05:09:31.481467: Pseudo dice [0.8178] 
2024-04-08 05:09:31.481527: Epoch time: 9.42 s 
2024-04-08 05:09:32.483054:  
2024-04-08 05:09:32.483322: Epoch 68 
2024-04-08 05:09:32.483534: Current learning rate: 0.00939 
2024-04-08 05:09:41.537602: train_loss -0.9024 
2024-04-08 05:09:41.537756: val_loss -0.7764 
2024-04-08 05:09:41.537830: Pseudo dice [0.8246] 
2024-04-08 05:09:41.537887: Epoch time: 9.06 s 
2024-04-08 05:09:42.534441:  
2024-04-08 05:09:42.534537: Epoch 69 
2024-04-08 05:09:42.534615: Current learning rate: 0.00938 
2024-04-08 05:09:51.887649: train_loss -0.9004 
2024-04-08 05:09:51.887821: val_loss -0.7613 
2024-04-08 05:09:51.887891: Pseudo dice [0.8108] 
2024-04-08 05:09:51.887954: Epoch time: 9.35 s 
2024-04-08 05:09:52.889150:  
2024-04-08 05:09:52.889254: Epoch 70 
2024-04-08 05:09:52.889335: Current learning rate: 0.00937 
2024-04-08 05:10:01.869959: train_loss -0.9018 
2024-04-08 05:10:01.870101: val_loss -0.7751 
2024-04-08 05:10:01.870179: Pseudo dice [0.8182] 
2024-04-08 05:10:01.870239: Epoch time: 8.98 s 
2024-04-08 05:10:02.867005:  
2024-04-08 05:10:02.867223: Epoch 71 
2024-04-08 05:10:02.867306: Current learning rate: 0.00936 
2024-04-08 05:10:12.087960: train_loss -0.9061 
2024-04-08 05:10:12.088264: val_loss -0.77 
2024-04-08 05:10:12.088334: Pseudo dice [0.822] 
2024-04-08 05:10:12.088462: Epoch time: 9.22 s 
2024-04-08 05:10:13.101352:  
2024-04-08 05:10:13.101467: Epoch 72 
2024-04-08 05:10:13.101592: Current learning rate: 0.00935 
2024-04-08 05:10:21.950210: train_loss -0.9065 
2024-04-08 05:10:21.950430: val_loss -0.772 
2024-04-08 05:10:21.950565: Pseudo dice [0.8195] 
2024-04-08 05:10:21.950645: Epoch time: 8.85 s 
2024-04-08 05:10:23.029163:  
2024-04-08 05:10:23.029315: Epoch 73 
2024-04-08 05:10:23.029429: Current learning rate: 0.00934 
2024-04-08 05:10:32.763762: train_loss -0.908 
2024-04-08 05:10:32.763949: val_loss -0.7784 
2024-04-08 05:10:32.764031: Pseudo dice [0.8302] 
2024-04-08 05:10:32.764111: Epoch time: 9.74 s 
2024-04-08 05:10:33.914120:  
2024-04-08 05:10:33.914241: Epoch 74 
2024-04-08 05:10:33.914318: Current learning rate: 0.00933 
2024-04-08 05:10:42.741415: train_loss -0.9088 
2024-04-08 05:10:42.741567: val_loss -0.7794 
2024-04-08 05:10:42.741631: Pseudo dice [0.8262] 
2024-04-08 05:10:42.741690: Epoch time: 8.83 s 
2024-04-08 05:10:43.782789:  
2024-04-08 05:10:43.782897: Epoch 75 
2024-04-08 05:10:43.782975: Current learning rate: 0.00932 
2024-04-08 05:10:53.219901: train_loss -0.9078 
2024-04-08 05:10:53.220192: val_loss -0.7877 
2024-04-08 05:10:53.220350: Pseudo dice [0.8316] 
2024-04-08 05:10:53.220546: Epoch time: 9.44 s 
2024-04-08 05:10:54.258620:  
2024-04-08 05:10:54.258933: Epoch 76 
2024-04-08 05:10:54.259021: Current learning rate: 0.00931 
2024-04-08 05:11:03.518654: train_loss -0.9117 
2024-04-08 05:11:03.518792: val_loss -0.7887 
2024-04-08 05:11:03.518850: Pseudo dice [0.8333] 
2024-04-08 05:11:03.518904: Epoch time: 9.26 s 
2024-04-08 05:11:04.525317:  
2024-04-08 05:11:04.525633: Epoch 77 
2024-04-08 05:11:04.525714: Current learning rate: 0.0093 
2024-04-08 05:11:13.871257: train_loss -0.9076 
2024-04-08 05:11:13.871545: val_loss -0.7842 
2024-04-08 05:11:13.871698: Pseudo dice [0.8295] 
2024-04-08 05:11:13.871862: Epoch time: 9.35 s 
2024-04-08 05:11:14.913033:  
2024-04-08 05:11:14.913135: Epoch 78 
2024-04-08 05:11:14.913232: Current learning rate: 0.0093 
2024-04-08 05:11:24.327382: train_loss -0.9102 
2024-04-08 05:11:24.327526: val_loss -0.7657 
2024-04-08 05:11:24.327585: Pseudo dice [0.8163] 
2024-04-08 05:11:24.327643: Epoch time: 9.42 s 
2024-04-08 05:11:25.489198:  
2024-04-08 05:11:25.489322: Epoch 79 
2024-04-08 05:11:25.489402: Current learning rate: 0.00929 
2024-04-08 05:11:34.388114: train_loss -0.9124 
2024-04-08 05:11:34.388329: val_loss -0.8014 
2024-04-08 05:11:34.388455: Pseudo dice [0.8435] 
2024-04-08 05:11:34.388675: Epoch time: 8.9 s 
2024-04-08 05:11:34.388741: Yayy! New best EMA pseudo Dice: 0.8254 
2024-04-08 05:11:35.551747:  
2024-04-08 05:11:35.551966: Epoch 80 
2024-04-08 05:11:35.552095: Current learning rate: 0.00928 
2024-04-08 05:11:44.682285: train_loss -0.9126 
2024-04-08 05:11:44.682433: val_loss -0.7672 
2024-04-08 05:11:44.682511: Pseudo dice [0.8159] 
2024-04-08 05:11:44.682570: Epoch time: 9.13 s 
2024-04-08 05:11:45.703112:  
2024-04-08 05:11:45.703518: Epoch 81 
2024-04-08 05:11:45.703602: Current learning rate: 0.00927 
2024-04-08 05:11:54.661673: train_loss -0.9142 
2024-04-08 05:11:54.661851: val_loss -0.7861 
2024-04-08 05:11:54.661947: Pseudo dice [0.8277] 
2024-04-08 05:11:54.662030: Epoch time: 8.96 s 
2024-04-08 05:11:55.757660:  
2024-04-08 05:11:55.757775: Epoch 82 
2024-04-08 05:11:55.757869: Current learning rate: 0.00926 
2024-04-08 05:12:05.129486: train_loss -0.9149 
2024-04-08 05:12:05.129754: val_loss -0.7848 
2024-04-08 05:12:05.130048: Pseudo dice [0.8276] 
2024-04-08 05:12:05.130201: Epoch time: 9.37 s 
2024-04-08 05:12:06.070969:  
2024-04-08 05:12:06.071068: Epoch 83 
2024-04-08 05:12:06.071162: Current learning rate: 0.00925 
2024-04-08 05:12:15.160199: train_loss -0.917 
2024-04-08 05:12:15.160355: val_loss -0.7711 
2024-04-08 05:12:15.160446: Pseudo dice [0.8208] 
2024-04-08 05:12:15.160547: Epoch time: 9.09 s 
2024-04-08 05:12:16.113701:  
2024-04-08 05:12:16.113798: Epoch 84 
2024-04-08 05:12:16.113892: Current learning rate: 0.00924 
2024-04-08 05:12:25.249755: train_loss -0.9181 
2024-04-08 05:12:25.249917: val_loss -0.7803 
2024-04-08 05:12:25.249983: Pseudo dice [0.8265] 
2024-04-08 05:12:25.250041: Epoch time: 9.14 s 
2024-04-08 05:12:26.210318:  
2024-04-08 05:12:26.210522: Epoch 85 
2024-04-08 05:12:26.210602: Current learning rate: 0.00923 
2024-04-08 05:12:35.554406: train_loss -0.9174 
2024-04-08 05:12:35.554552: val_loss -0.8 
2024-04-08 05:12:35.554612: Pseudo dice [0.8463] 
2024-04-08 05:12:35.554671: Epoch time: 9.34 s 
2024-04-08 05:12:35.554720: Yayy! New best EMA pseudo Dice: 0.827 
2024-04-08 05:12:36.582854:  
2024-04-08 05:12:36.582956: Epoch 86 
2024-04-08 05:12:36.583035: Current learning rate: 0.00922 
2024-04-08 05:12:45.584343: train_loss -0.913 
2024-04-08 05:12:45.584651: val_loss -0.7704 
2024-04-08 05:12:45.584807: Pseudo dice [0.815] 
2024-04-08 05:12:45.584971: Epoch time: 9.0 s 
2024-04-08 05:12:46.576778:  
2024-04-08 05:12:46.576886: Epoch 87 
2024-04-08 05:12:46.576964: Current learning rate: 0.00921 
2024-04-08 05:12:55.932493: train_loss -0.9161 
2024-04-08 05:12:55.932640: val_loss -0.7748 
2024-04-08 05:12:55.932702: Pseudo dice [0.82] 
2024-04-08 05:12:55.932760: Epoch time: 9.36 s 
2024-04-08 05:12:56.886619:  
2024-04-08 05:12:56.886720: Epoch 88 
2024-04-08 05:12:56.886816: Current learning rate: 0.0092 
2024-04-08 05:13:06.212577: train_loss -0.9176 
2024-04-08 05:13:06.212810: val_loss -0.7795 
2024-04-08 05:13:06.212908: Pseudo dice [0.8281] 
2024-04-08 05:13:06.213012: Epoch time: 9.33 s 
2024-04-08 05:13:07.201755:  
2024-04-08 05:13:07.201854: Epoch 89 
2024-04-08 05:13:07.201947: Current learning rate: 0.0092 
2024-04-08 05:13:16.529399: train_loss -0.9153 
2024-04-08 05:13:16.529583: val_loss -0.7818 
2024-04-08 05:13:16.529674: Pseudo dice [0.8258] 
2024-04-08 05:13:16.529763: Epoch time: 9.33 s 
2024-04-08 05:13:17.677311:  
2024-04-08 05:13:17.677413: Epoch 90 
2024-04-08 05:13:17.677492: Current learning rate: 0.00919 
2024-04-08 05:13:26.895703: train_loss -0.9148 
2024-04-08 05:13:26.896057: val_loss -0.7748 
2024-04-08 05:13:26.896119: Pseudo dice [0.8256] 
2024-04-08 05:13:26.896230: Epoch time: 9.22 s 
2024-04-08 05:13:27.852039:  
2024-04-08 05:13:27.852142: Epoch 91 
2024-04-08 05:13:27.852235: Current learning rate: 0.00918 
2024-04-08 05:13:37.214335: train_loss -0.9127 
2024-04-08 05:13:37.214476: val_loss -0.762 
2024-04-08 05:13:37.214532: Pseudo dice [0.8107] 
2024-04-08 05:13:37.214605: Epoch time: 9.36 s 
2024-04-08 05:13:38.143294:  
2024-04-08 05:13:38.143394: Epoch 92 
2024-04-08 05:13:38.143473: Current learning rate: 0.00917 
2024-04-08 05:13:46.973535: train_loss -0.9196 
2024-04-08 05:13:46.974112: val_loss -0.7808 
2024-04-08 05:13:46.974184: Pseudo dice [0.8245] 
2024-04-08 05:13:46.974237: Epoch time: 8.83 s 
2024-04-08 05:13:47.927157:  
2024-04-08 05:13:47.927256: Epoch 93 
2024-04-08 05:13:47.927345: Current learning rate: 0.00916 
2024-04-08 05:13:56.839488: train_loss -0.9193 
2024-04-08 05:13:56.839707: val_loss -0.7862 
2024-04-08 05:13:56.839833: Pseudo dice [0.8316] 
2024-04-08 05:13:56.839920: Epoch time: 8.91 s 
2024-04-08 05:13:57.804933:  
2024-04-08 05:13:57.805036: Epoch 94 
2024-04-08 05:13:57.805115: Current learning rate: 0.00915 
2024-04-08 05:14:06.843572: train_loss -0.9202 
2024-04-08 05:14:06.843755: val_loss -0.7745 
2024-04-08 05:14:06.843825: Pseudo dice [0.8226] 
2024-04-08 05:14:06.843890: Epoch time: 9.04 s 
2024-04-08 05:14:07.783829:  
2024-04-08 05:14:07.784010: Epoch 95 
2024-04-08 05:14:07.784110: Current learning rate: 0.00914 
2024-04-08 05:14:16.871768: train_loss -0.9186 
2024-04-08 05:14:16.871917: val_loss -0.7836 
2024-04-08 05:14:16.872018: Pseudo dice [0.8292] 
2024-04-08 05:14:16.872075: Epoch time: 9.09 s 
2024-04-08 05:14:17.838258:  
2024-04-08 05:14:17.838387: Epoch 96 
2024-04-08 05:14:17.838464: Current learning rate: 0.00913 
2024-04-08 05:14:27.187617: train_loss -0.9188 
2024-04-08 05:14:27.187855: val_loss -0.785 
2024-04-08 05:14:27.187999: Pseudo dice [0.8254] 
2024-04-08 05:14:27.188248: Epoch time: 9.35 s 
2024-04-08 05:14:28.211545:  
2024-04-08 05:14:28.211673: Epoch 97 
2024-04-08 05:14:28.211752: Current learning rate: 0.00912 
2024-04-08 05:14:36.812423: train_loss -0.9201 
2024-04-08 05:14:36.812653: val_loss -0.7741 
2024-04-08 05:14:36.812762: Pseudo dice [0.8214] 
2024-04-08 05:14:36.812867: Epoch time: 8.6 s 
2024-04-08 05:14:37.809234:  
2024-04-08 05:14:37.809339: Epoch 98 
2024-04-08 05:14:37.809418: Current learning rate: 0.00911 
2024-04-08 05:14:46.937992: train_loss -0.9246 
2024-04-08 05:14:46.938145: val_loss -0.7642 
2024-04-08 05:14:46.938209: Pseudo dice [0.8129] 
2024-04-08 05:14:46.938272: Epoch time: 9.13 s 
2024-04-08 05:14:47.956234:  
2024-04-08 05:14:47.956335: Epoch 99 
2024-04-08 05:14:47.956421: Current learning rate: 0.0091 
2024-04-08 05:14:57.456171: train_loss -0.9207 
2024-04-08 05:14:57.456366: val_loss -0.7721 
2024-04-08 05:14:57.456700: Pseudo dice [0.8281] 
2024-04-08 05:14:57.456843: Epoch time: 9.5 s 
2024-04-08 05:14:58.547507:  
2024-04-08 05:14:58.547824: Epoch 100 
2024-04-08 05:14:58.547945: Current learning rate: 0.0091 
2024-04-08 05:15:08.269114: train_loss -0.9198 
2024-04-08 05:15:08.269333: val_loss -0.7844 
2024-04-08 05:15:08.269426: Pseudo dice [0.8273] 
2024-04-08 05:15:08.269544: Epoch time: 9.72 s 
2024-04-08 05:15:09.328907:  
2024-04-08 05:15:09.329010: Epoch 101 
2024-04-08 05:15:09.329106: Current learning rate: 0.00909 
2024-04-08 05:15:18.707292: train_loss -0.9201 
2024-04-08 05:15:18.707448: val_loss -0.7848 
2024-04-08 05:15:18.707530: Pseudo dice [0.833] 
2024-04-08 05:15:18.707606: Epoch time: 9.38 s 
2024-04-08 05:15:19.816805:  
2024-04-08 05:15:19.816910: Epoch 102 
2024-04-08 05:15:19.816989: Current learning rate: 0.00908 
2024-04-08 05:15:28.890739: train_loss -0.9222 
2024-04-08 05:15:28.890920: val_loss -0.7696 
2024-04-08 05:15:28.891108: Pseudo dice [0.8145] 
2024-04-08 05:15:28.891212: Epoch time: 9.07 s 
2024-04-08 05:15:29.840925:  
2024-04-08 05:15:29.841035: Epoch 103 
2024-04-08 05:15:29.841116: Current learning rate: 0.00907 
2024-04-08 05:15:39.118474: train_loss -0.9226 
2024-04-08 05:15:39.118630: val_loss -0.782 
2024-04-08 05:15:39.118842: Pseudo dice [0.824] 
2024-04-08 05:15:39.118946: Epoch time: 9.28 s 
2024-04-08 05:15:40.153960:  
2024-04-08 05:15:40.154078: Epoch 104 
2024-04-08 05:15:40.154157: Current learning rate: 0.00906 
2024-04-08 05:15:48.806072: train_loss -0.9249 
2024-04-08 05:15:48.806277: val_loss -0.7956 
2024-04-08 05:15:48.806418: Pseudo dice [0.8379] 
2024-04-08 05:15:48.806484: Epoch time: 8.65 s 
2024-04-08 05:15:49.773846:  
2024-04-08 05:15:49.773948: Epoch 105 
2024-04-08 05:15:49.774024: Current learning rate: 0.00905 
2024-04-08 05:15:58.885976: train_loss -0.9248 
2024-04-08 05:15:58.886381: val_loss -0.7839 
2024-04-08 05:15:58.886495: Pseudo dice [0.8325] 
2024-04-08 05:15:58.886715: Epoch time: 9.11 s 
2024-04-08 05:16:00.046314:  
2024-04-08 05:16:00.046421: Epoch 106 
2024-04-08 05:16:00.046501: Current learning rate: 0.00904 
2024-04-08 05:16:09.397772: train_loss -0.9229 
2024-04-08 05:16:09.397979: val_loss -0.786 
2024-04-08 05:16:09.398062: Pseudo dice [0.8305] 
2024-04-08 05:16:09.398154: Epoch time: 9.35 s 
2024-04-08 05:16:10.350824:  
2024-04-08 05:16:10.350923: Epoch 107 
2024-04-08 05:16:10.351043: Current learning rate: 0.00903 
2024-04-08 05:16:19.536049: train_loss -0.9258 
2024-04-08 05:16:19.536383: val_loss -0.7708 
2024-04-08 05:16:19.536959: Pseudo dice [0.8197] 
2024-04-08 05:16:19.537018: Epoch time: 9.19 s 
2024-04-08 05:16:20.493227:  
2024-04-08 05:16:20.493330: Epoch 108 
2024-04-08 05:16:20.493406: Current learning rate: 0.00902 
2024-04-08 05:16:29.346718: train_loss -0.9266 
2024-04-08 05:16:29.346902: val_loss -0.7771 
2024-04-08 05:16:29.346968: Pseudo dice [0.825] 
2024-04-08 05:16:29.347119: Epoch time: 8.85 s 
2024-04-08 05:16:30.302724:  
2024-04-08 05:16:30.302822: Epoch 109 
2024-04-08 05:16:30.302901: Current learning rate: 0.00901 
2024-04-08 05:16:39.351805: train_loss -0.9261 
2024-04-08 05:16:39.351946: val_loss -0.7741 
2024-04-08 05:16:39.352008: Pseudo dice [0.8262] 
2024-04-08 05:16:39.352067: Epoch time: 9.05 s 
2024-04-08 05:16:40.382291:  
2024-04-08 05:16:40.382389: Epoch 110 
2024-04-08 05:16:40.382478: Current learning rate: 0.009 
2024-04-08 05:16:49.503824: train_loss -0.9223 
2024-04-08 05:16:49.503970: val_loss -0.7752 
2024-04-08 05:16:49.504031: Pseudo dice [0.821] 
2024-04-08 05:16:49.504091: Epoch time: 9.12 s 
2024-04-08 05:16:50.488970:  
2024-04-08 05:16:50.489307: Epoch 111 
2024-04-08 05:16:50.489388: Current learning rate: 0.009 
2024-04-08 05:17:00.065006: train_loss -0.9201 
2024-04-08 05:17:00.065166: val_loss -0.7597 
2024-04-08 05:17:00.065231: Pseudo dice [0.8097] 
2024-04-08 05:17:00.065294: Epoch time: 9.58 s 
2024-04-08 05:17:01.188725:  
2024-04-08 05:17:01.188831: Epoch 112 
2024-04-08 05:17:01.188927: Current learning rate: 0.00899 
2024-04-08 05:17:10.023674: train_loss -0.9196 
2024-04-08 05:17:10.023867: val_loss -0.771 
2024-04-08 05:17:10.024029: Pseudo dice [0.824] 
2024-04-08 05:17:10.024236: Epoch time: 8.84 s 
2024-04-08 05:17:10.995387:  
2024-04-08 05:17:10.995495: Epoch 113 
2024-04-08 05:17:10.995573: Current learning rate: 0.00898 
2024-04-08 05:17:20.354457: train_loss -0.9236 
2024-04-08 05:17:20.354601: val_loss -0.7561 
2024-04-08 05:17:20.354666: Pseudo dice [0.8053] 
2024-04-08 05:17:20.354725: Epoch time: 9.36 s 
2024-04-08 05:17:21.324320:  
2024-04-08 05:17:21.324442: Epoch 114 
2024-04-08 05:17:21.324524: Current learning rate: 0.00897 
2024-04-08 05:17:30.515751: train_loss -0.9234 
2024-04-08 05:17:30.515972: val_loss -0.7608 
2024-04-08 05:17:30.516155: Pseudo dice [0.8114] 
2024-04-08 05:17:30.516284: Epoch time: 9.19 s 
2024-04-08 05:17:31.474724:  
2024-04-08 05:17:31.474842: Epoch 115 
2024-04-08 05:17:31.474935: Current learning rate: 0.00896 
2024-04-08 05:17:40.333541: train_loss -0.9252 
2024-04-08 05:17:40.333689: val_loss -0.7755 
2024-04-08 05:17:40.333771: Pseudo dice [0.8224] 
2024-04-08 05:17:40.333827: Epoch time: 8.86 s 
2024-04-08 05:17:41.337775:  
2024-04-08 05:17:41.337871: Epoch 116 
2024-04-08 05:17:41.337982: Current learning rate: 0.00895 
2024-04-08 05:17:50.571713: train_loss -0.9264 
2024-04-08 05:17:50.571947: val_loss -0.7654 
2024-04-08 05:17:50.572077: Pseudo dice [0.8155] 
2024-04-08 05:17:50.572194: Epoch time: 9.23 s 
2024-04-08 05:17:51.747638:  
2024-04-08 05:17:51.747744: Epoch 117 
2024-04-08 05:17:51.747839: Current learning rate: 0.00894 
2024-04-08 05:18:00.953480: train_loss -0.9285 
2024-04-08 05:18:00.953782: val_loss -0.7759 
2024-04-08 05:18:00.953940: Pseudo dice [0.827] 
2024-04-08 05:18:00.954105: Epoch time: 9.21 s 
2024-04-08 05:18:01.949372:  
2024-04-08 05:18:01.949497: Epoch 118 
2024-04-08 05:18:01.949574: Current learning rate: 0.00893 
2024-04-08 05:18:11.119964: train_loss -0.9265 
2024-04-08 05:18:11.120143: val_loss -0.7882 
2024-04-08 05:18:11.120337: Pseudo dice [0.8298] 
2024-04-08 05:18:11.120409: Epoch time: 9.17 s 
2024-04-08 05:18:12.192565:  
2024-04-08 05:18:12.192762: Epoch 119 
2024-04-08 05:18:12.192848: Current learning rate: 0.00892 
2024-04-08 05:18:21.475728: train_loss -0.926 
2024-04-08 05:18:21.475870: val_loss -0.7742 
2024-04-08 05:18:21.475928: Pseudo dice [0.8214] 
2024-04-08 05:18:21.476002: Epoch time: 9.28 s 
2024-04-08 05:18:22.484216:  
2024-04-08 05:18:22.484315: Epoch 120 
2024-04-08 05:18:22.484392: Current learning rate: 0.00891 
2024-04-08 05:18:31.474533: train_loss -0.9253 
2024-04-08 05:18:31.474694: val_loss -0.7763 
2024-04-08 05:18:31.474755: Pseudo dice [0.8258] 
2024-04-08 05:18:31.474815: Epoch time: 8.99 s 
2024-04-08 05:18:32.456350:  
2024-04-08 05:18:32.456489: Epoch 121 
2024-04-08 05:18:32.456573: Current learning rate: 0.0089 
2024-04-08 05:18:41.792402: train_loss -0.9266 
2024-04-08 05:18:41.792584: val_loss -0.7782 
2024-04-08 05:18:41.792649: Pseudo dice [0.8234] 
2024-04-08 05:18:41.792711: Epoch time: 9.34 s 
2024-04-08 05:18:42.773423:  
2024-04-08 05:18:42.773523: Epoch 122 
2024-04-08 05:18:42.773601: Current learning rate: 0.00889 
2024-04-08 05:18:52.242055: train_loss -0.9267 
2024-04-08 05:18:52.242206: val_loss -0.7712 
2024-04-08 05:18:52.242284: Pseudo dice [0.8199] 
2024-04-08 05:18:52.242348: Epoch time: 9.47 s 
2024-04-08 05:18:53.404014:  
2024-04-08 05:18:53.404235: Epoch 123 
2024-04-08 05:18:53.404319: Current learning rate: 0.00889 
2024-04-08 05:19:02.840230: train_loss -0.9243 
2024-04-08 05:19:02.840378: val_loss -0.7784 
2024-04-08 05:19:02.840442: Pseudo dice [0.8256] 
2024-04-08 05:19:02.840519: Epoch time: 9.44 s 
2024-04-08 05:19:03.919486:  
2024-04-08 05:19:03.919593: Epoch 124 
2024-04-08 05:19:03.919688: Current learning rate: 0.00888 
2024-04-08 05:19:12.903838: train_loss -0.9251 
2024-04-08 05:19:12.904066: val_loss -0.7756 
2024-04-08 05:19:12.904131: Pseudo dice [0.8232] 
2024-04-08 05:19:12.904244: Epoch time: 8.99 s 
2024-04-08 05:19:13.875008:  
2024-04-08 05:19:13.875126: Epoch 125 
2024-04-08 05:19:13.875221: Current learning rate: 0.00887 
2024-04-08 05:19:22.925613: train_loss -0.9245 
2024-04-08 05:19:22.925885: val_loss -0.7732 
2024-04-08 05:19:22.926079: Pseudo dice [0.8222] 
2024-04-08 05:19:22.926143: Epoch time: 9.05 s 
2024-04-08 05:19:23.922318:  
2024-04-08 05:19:23.922450: Epoch 126 
2024-04-08 05:19:23.922534: Current learning rate: 0.00886 
2024-04-08 05:19:32.743712: train_loss -0.9239 
2024-04-08 05:19:32.744082: val_loss -0.794 
2024-04-08 05:19:32.744203: Pseudo dice [0.8393] 
2024-04-08 05:19:32.744301: Epoch time: 8.82 s 
2024-04-08 05:19:33.766292:  
2024-04-08 05:19:33.766388: Epoch 127 
2024-04-08 05:19:33.766496: Current learning rate: 0.00885 
2024-04-08 05:19:42.992001: train_loss -0.9264 
2024-04-08 05:19:42.992391: val_loss -0.7816 
2024-04-08 05:19:42.992671: Pseudo dice [0.8307] 
2024-04-08 05:19:42.992891: Epoch time: 9.23 s 
2024-04-08 05:19:44.153822:  
2024-04-08 05:19:44.154061: Epoch 128 
2024-04-08 05:19:44.154148: Current learning rate: 0.00884 
2024-04-08 05:19:53.058074: train_loss -0.9267 
2024-04-08 05:19:53.058251: val_loss -0.7813 
2024-04-08 05:19:53.058494: Pseudo dice [0.8303] 
2024-04-08 05:19:53.058602: Epoch time: 8.9 s 
2024-04-08 05:19:54.190673:  
2024-04-08 05:19:54.190881: Epoch 129 
2024-04-08 05:19:54.190966: Current learning rate: 0.00883 
2024-04-08 05:20:03.329015: train_loss -0.9289 
2024-04-08 05:20:03.329179: val_loss -0.779 
2024-04-08 05:20:03.329257: Pseudo dice [0.8271] 
2024-04-08 05:20:03.329333: Epoch time: 9.14 s 
2024-04-08 05:20:04.352399:  
2024-04-08 05:20:04.352529: Epoch 130 
2024-04-08 05:20:04.352607: Current learning rate: 0.00882 
2024-04-08 05:20:13.215326: train_loss -0.9281 
2024-04-08 05:20:13.215611: val_loss -0.7974 
2024-04-08 05:20:13.215763: Pseudo dice [0.8401] 
2024-04-08 05:20:13.215927: Epoch time: 8.86 s 
2024-04-08 05:20:13.216063: Yayy! New best EMA pseudo Dice: 0.827 
2024-04-08 05:20:14.366416:  
2024-04-08 05:20:14.366519: Epoch 131 
2024-04-08 05:20:14.366615: Current learning rate: 0.00881 
2024-04-08 05:20:23.521011: train_loss -0.9307 
2024-04-08 05:20:23.521202: val_loss -0.7754 
2024-04-08 05:20:23.521365: Pseudo dice [0.8239] 
2024-04-08 05:20:23.521556: Epoch time: 9.16 s 
2024-04-08 05:20:24.722562:  
2024-04-08 05:20:24.722772: Epoch 132 
2024-04-08 05:20:24.722853: Current learning rate: 0.0088 
2024-04-08 05:20:34.304204: train_loss -0.932 
2024-04-08 05:20:34.304367: val_loss -0.7695 
2024-04-08 05:20:34.304437: Pseudo dice [0.8234] 
2024-04-08 05:20:34.304496: Epoch time: 9.58 s 
2024-04-08 05:20:35.466072:  
2024-04-08 05:20:35.466180: Epoch 133 
2024-04-08 05:20:35.466258: Current learning rate: 0.00879 
2024-04-08 05:20:45.032937: train_loss -0.9292 
2024-04-08 05:20:45.033086: val_loss -0.7694 
2024-04-08 05:20:45.033147: Pseudo dice [0.8178] 
2024-04-08 05:20:45.033206: Epoch time: 9.57 s 
2024-04-08 05:20:46.003806:  
2024-04-08 05:20:46.003938: Epoch 134 
2024-04-08 05:20:46.004017: Current learning rate: 0.00879 
2024-04-08 05:20:55.315659: train_loss -0.9304 
2024-04-08 05:20:55.315815: val_loss -0.7796 
2024-04-08 05:20:55.315879: Pseudo dice [0.8245] 
2024-04-08 05:20:55.315940: Epoch time: 9.31 s 
2024-04-08 05:20:56.300893:  
2024-04-08 05:20:56.301133: Epoch 135 
2024-04-08 05:20:56.301309: Current learning rate: 0.00878 
2024-04-08 05:21:05.601575: train_loss -0.9284 
2024-04-08 05:21:05.601783: val_loss -0.7824 
2024-04-08 05:21:05.601892: Pseudo dice [0.8331] 
2024-04-08 05:21:05.602106: Epoch time: 9.3 s 
2024-04-08 05:21:06.630515:  
2024-04-08 05:21:06.630621: Epoch 136 
2024-04-08 05:21:06.630699: Current learning rate: 0.00877 
2024-04-08 05:21:15.721877: train_loss -0.9306 
2024-04-08 05:21:15.722017: val_loss -0.7759 
2024-04-08 05:21:15.722071: Pseudo dice [0.8246] 
2024-04-08 05:21:15.722126: Epoch time: 9.09 s 
2024-04-08 05:21:16.751510:  
2024-04-08 05:21:16.751696: Epoch 137 
2024-04-08 05:21:16.751778: Current learning rate: 0.00876 
2024-04-08 05:21:25.940809: train_loss -0.9295 
2024-04-08 05:21:25.940957: val_loss -0.7812 
2024-04-08 05:21:25.941018: Pseudo dice [0.8254] 
2024-04-08 05:21:25.941076: Epoch time: 9.19 s 
2024-04-08 05:21:27.152201:  
2024-04-08 05:21:27.152332: Epoch 138 
2024-04-08 05:21:27.152411: Current learning rate: 0.00875 
2024-04-08 05:21:36.641839: train_loss -0.9281 
2024-04-08 05:21:36.642192: val_loss -0.7713 
2024-04-08 05:21:36.642398: Pseudo dice [0.8189] 
2024-04-08 05:21:36.642490: Epoch time: 9.49 s 
2024-04-08 05:21:37.642203:  
2024-04-08 05:21:37.642311: Epoch 139 
2024-04-08 05:21:37.642388: Current learning rate: 0.00874 
2024-04-08 05:21:46.493212: train_loss -0.9293 
2024-04-08 05:21:46.493360: val_loss -0.7748 
2024-04-08 05:21:46.493422: Pseudo dice [0.8223] 
2024-04-08 05:21:46.493481: Epoch time: 8.85 s 
2024-04-08 05:21:47.479975:  
2024-04-08 05:21:47.480073: Epoch 140 
2024-04-08 05:21:47.480165: Current learning rate: 0.00873 
2024-04-08 05:21:56.933748: train_loss -0.9289 
2024-04-08 05:21:56.933887: val_loss -0.7742 
2024-04-08 05:21:56.933950: Pseudo dice [0.8248] 
2024-04-08 05:21:56.934010: Epoch time: 9.45 s 
2024-04-08 05:21:57.943136:  
2024-04-08 05:21:57.943236: Epoch 141 
2024-04-08 05:21:57.943311: Current learning rate: 0.00872 
2024-04-08 05:22:07.392906: train_loss -0.9321 
2024-04-08 05:22:07.393345: val_loss -0.7843 
2024-04-08 05:22:07.393604: Pseudo dice [0.8277] 
2024-04-08 05:22:07.393715: Epoch time: 9.45 s 
2024-04-08 05:22:08.454162:  
2024-04-08 05:22:08.454277: Epoch 142 
2024-04-08 05:22:08.454359: Current learning rate: 0.00871 
2024-04-08 05:22:17.813583: train_loss -0.9325 
2024-04-08 05:22:17.813735: val_loss -0.7808 
2024-04-08 05:22:17.813797: Pseudo dice [0.8279] 
2024-04-08 05:22:17.813861: Epoch time: 9.36 s 
2024-04-08 05:22:18.872439:  
2024-04-08 05:22:18.872559: Epoch 143 
2024-04-08 05:22:18.872642: Current learning rate: 0.0087 
